---
title: "**The Economics of App Success: How Revenue Streams Influence Downloads and User Ratings**"
subtitle: "Group Assignment - Strategy and Business Models"
author: "Group 5"
date: "November 28, 2024"
date-format: DD/MM/YYYY # Set date format to long
crossref:
  fig-prefix: Figure   # (default is "Figure")
  tbl-prefix: Table    # (default is "Table")
format: 
  pdf: #Output pdf
    documentclass: article
    fig-pos: "H"
    number-sections: true
    toc: true #table of contents
    toc-title: Contents #name table of contents
    papersize: a4
    fontsize: 12pt
    fontfamily: mathptmx
    geometry:
      - top=25mm #top margin
      - left=25mm #left margin
    pdf-engine: pdflatex
    cap-location: bottom # Set table caption location to bottom
    include-in-header: 
      - text: |
          \usepackage{graphicx}
    include-before-body:
      - text: |
          \vspace{2em}
          \begin{center}
            \includegraphics[width=0.3\textwidth]{figures/jads.png}
          \end{center}
          \vspace{3em}
          \newpage
bibliography: references.bib
bibliographystyle: apa
execute: 
  enabled: true
jupyter: python3
---

<!-- horizontal line -->

\newpage

# Introduction <!-- 800-1,000 words -->

<!-- Content: Introduce the topic and explain its relevance in both academic and practical contexts. Justify the research gap and formulate a clear and insightful research question.  Key Elements: Background of the topic. Identification of the research gap. Relevance to current business practices. Research question. -->

With the every-growing popularity of cellphones [@charted2023], the popularity of mobile applications is also steadily increasing. In 2024, mobile applications are estimated to generate over \$900 billion in revenue [@global2019]. Generally, mobile applications ('*apps*' from here on) tend to be categorized in three different categories [@roma2016]. Paid apps are the most transparent; they revenue is based on an up-front purchase by the user. Free apps, on the other hand, require no purchase by the user at any stage. According to @roma2016, these apps make their revenue from deals with third-parties, either through advertisement or other purposes such as market information.

Finally, freemium apps are, as the name suggests, a middle-ground between free and premium. Users get access to a basic version of the application first and can unlock more features through an in-app payment [@kumar2014]. Of these three revenue models, freemium is the most commonly used and the most [@salehudin2021] and leads to more downloads as well as revenue [@liu2014].

## Academic Background

<!-- Kort samengevat: Wat is de wetenschappelijke consensus over dit topic? Dit wordt verder uitgediept in de Theory and Hypothesis sectie.-->

Most research uses these three established categories—paid, freemium, and free—when discussing revenue models for apps. However, by limiting the discussion to these three terms, nuances within these categories might be missed.

In a review paper from 2023 [@djaruma2023], different levels of monetization are suggested based on previous literature. These levels provide a clear framework for the revenue models of mobile apps, and are briefly summarized in @tbl-levels.

| Strategy | Description |
|-------------------------|-----------------------------------------------|
| Level 5: Premium | Pay to use the application. This either happens up-front, or after a trial period. |
| Level 4: Semi-premium | Use a limited number of features for free. Unlock the app with all features through an in-app purchase. |
| Level 3: In-app advertisement and in-app purchases | Free application with ads, encouraging users to remove ads or to make in-app purchases. |
| Level 2: Sample and premium | Two different versions of the same app. One is a version with limit features and/or ads. The other version is a premium version. |
| Level 1: In-app advertisement | Only one version of the app, with only ads and no in-app purchases. |
| Level 0: Free | The app has no monetization. However, money can still be made through selling user information. |

: Six levels of monetization for apps {#tbl-levels}

The monetization levels as shown in @tbl-levels are not meant to illustrate the revenue a firm will earn. It is meant to show how much customers may engage in paying for features or services at different levels.

Level 0 is an app that is completely free to use. This requires no payment nor ads, but may still make revenue through selling user data. This risks both ethical pitfalls, as well as scrutiny from customers [@djaruma2023].

Level 1 is an app that requires no user payment, and only makes revenue through ads. These may also make revenue by selling user information. Large social media apps such as Facebook and Instagram fall in this category [@djaruma2023].

Level 2 allows the user to purchase either a free or premium version. The free app has limit features; if the user wants to experience the app in full, they will have to purchase the premium version. However, this does run the risk of 'cannibalization', wherein users never upgrade to the premium version. Therefore, it is of the utmost importance to find the right amount of features to include in the free version [@djaruma2023].

Level 3 combines advertisement and purchases. Many pay-to-win games use this strategy [@nieborg2016]: users can sit through ads and wait a long time for certain rewards, or they can pay for immediate rewards.

Level 4 is similar to level 2: a user has a free trial version, and can upgrade to a premium version. This is often seen in subscription-style apps [@chen2023].

Level 5 is a totally premium app, where a user has to pay up-front to access as features. This level requires a high-quality app, as users will not pay for an app that is not polished.

<!-- Ik heb dit expres kort gehouden, aangezien we ook nog een uitgebreidere literatuur review hebben. Maar, misschien moet dit toch nog iets langer? -Noa -->

## Societal Background

<!-- Is there any tie to practical contexts? How is this relevant to current business practices? -->

Currently, most apps utilize the freemium revenue model [@salehudin2021]. However, as discussed in @djaruma2023, there are many revenue models between completely premium and completely free. A more fine-grained classification of app revenue models beyond the traditional "paid-freemium-free" framework holds significant societal and business implications.

For society, such distinctions enhance transparency. Some monetization models, such as free or ad-filled apps, may rely on selling user information as a source of revenue [@bamberger2020]. Therefore, clearer distinctions regarding the revenue model will empower consumers to make informed choices. It may also enable policymakers to identify and regulate exploitative practices, such as manipulative microtransactions or intrusive ad models, ensuring all applications align with ethical and legal standards [@mileros2024].

For businesses, this paper should unlock more insight into the effectiveness of different revenue streams. This will allow developers to tailor monetization strategies to specific audiences. Furthermore, both consumers and regulatory bodies are growing more concerned with the privacy concerns of apps, especially ones that rely on market information [@mileros2024]. A granular understanding helps businesses adapt, aligning profitability with sustainability and ethical considerations.

<!-- Ik ben niet helemaal blij met de flow van dit stuk, ik mis een mooie conclusie. Maar, ik kan niet bedenken :(. Dit moet later toegevoegd worden -Noa. -->

## Research Gap

<!-- Kort samengevat: Wat is de relevantie? -->

In short, apps play an increasingly important role in our techno-centric society. To improve the user experience and increase profits, consideration of revenue models is key. Despite the great depth of research on this topic, literature tends to be focussed on the three big categories of paid, freemium, and free. This lack of nuance prevents us from understanding the fine-grained details that may help improve future apps.

<!-- Wat is de research gap? En wat is dus de onderzoekvraag? -->

The levels of monetization proposed by @djaruma2023 offer an opportunity to capture this nuance. However, no empirical study has yet applied their framework, as their paper was published only last year. By using this framework to examine how different revenue streams impact app popularity, this study aims to provide valuable insights into consumer preferences. Therefore, this paper seeks to answer the question: *How are the six different revenue models proposed by @djaruma2023 correlated with app success?*

<!-- Wederom: kort maar krachtig, of té kort? -Noa -->

# Theory and Hypotheses <!-- 1,000-1,200 words -->

<!--   Comprehensive coverage of relevant literature, effectively building towards the research question. Development of up to three hypotheses, clearly grounded in the theoretical framework.  Content: Review relevant literature to build a strong theoretical framework. Develop up to three hypotheses that directly connect to the theory and research question.  Key Elements: Comprehensive literature review. Explanation of key theoretical concepts. Development of hypotheses. -->

In this section, prior research into the topic of revenue streams and its correlation to success in apps will be discussed. As mentioned in the Introduction section, this paper will apply the six levels of revenue as proposed by @djaruma2023 to app data. The following section will contain a holistic overview of the existing research, as well as hypotheses that arise from this theoretical framework.

## Literature Review {#sec-literature-review}

According to @djaruma2023, there are six distinct revenue strategies for apps. However, it is important to point out they were not the inventors of these revenue strategies; these arose from the literature they analyzed. In the following section, we shall look at the previous research into these revenue strategies.

Firstly, biggest portion of apps are free to download. In fact, this contributes over 95% of all apps in both the Google Play Store as well as the IOS App Store [@statista2023apps]. But, this does not mean the apps do not generate revenue; they might implement advertisements, in-app purchases or sample and premium versions to still make a profit.

@sensortower2023forecast has predicted global spending on in-app advertisements will reach over 233 billion U.S. dollars in 2026. These funds are an important source of income for mobile app developers [@gao2022; @maddodi2023].

Aside from advertisements, there are two different revenue strategies to consider: in-app purchases, and a trial and premium version of the same app. Both of these are considered "freemium" in recent literature. @kumar2014 describes freemium as apps for which users get basic features for free and can update it using a payment. This can be done both through in-app payments, as well as purchasing the premium version of an app.

Another revenue strategy used in apps are in-app payments. This strategy is often used in games. More specifically, games that fall in the "pay-to-win" category [@nieborg2016]. These games often require the user to wait or watch advertisements, which they can circumvent by paying. Some games also allow users to buy special features, such as the look of their avatar or special powers. Nonetheless, while in-app purchases are a proven revenue strategy, it does come with risks. Notably, in-app payments are also prone to security risks, as it requires more complex interactions and involves more participants than traditional payment [@yang2019]. Therefore, developers need to make sure their payment methods are secure before launching an app with this revenue strategy.

In-app purchases are not the only solution for offering freemium services. A different method is offering two different versions: a free one, and a paid one. The free version often has limit features combined with ads, meaning you make a profit by advertisements [@appel2020]. This is combined with the revenue of the premium version.

To answer the question "*How are the six different revenue models as proposed by @djaruma2023 correlate to the success of an app?*", we must first define what constitutes to success. In this paper, success will be defined by a couple of factors: popularity, rating, and estimated revenue.

### Popularity

The popularity of an app can be measured by the number of downloads. It is important to note the popularity of an app is complex, and is not solely dependent on the chosen revenue model. Other features, such as whether an app is featured on charts, whether it has frequent updates, and word-of-mouth awareness, will also impact the popularity of an app [@aydingokgoz2021]. However, despite these other variables, to versions of the same app will still have drastically different performances with different revenue streams [@liu2014].

Building on this, we hypothesize that revenue models associated with fewer barriers to entry will drive higher downloads overall, but the impact of these models may vary by app type and market context.

*H1a: Apps that allow the user to have free access to all features (level 0 and 1) will have the highest amount of downloads overall.*

As @djaruma2023 has shown, the most highly ranked apps are level 1. These apps are the big social media platforms such as Instagram and Facebook. Therefore, we expect this to be reflected within our data and the following to be true.

*H1b: The apps with the most downloads will be level 1.*

Freemium apps can be implemented with either in-app purchases or different versions. For the latter, we expect more downloads to be generated by the free app, than its premium counterpart. As demonstrated by @liu2012freemium, users tend to download the trial version before committing to a premium version. Thus, the following is likely to be true.

*H1c: For apps that utilize a sample and a premium version of the same app (level 2), the free versions of an app will have more downloads than their paid-for counterpart.*

Finally, many games use a pay-to-win mechanism [@nieborg2016]. Therefore, we expect these in-app payment constructions to be used for most highly downloaded games.

*H1d: The most downloaded apps in the gaming category will likely fall under level 3 and 4.*

### Rating

The downloads of an app are not everything. An app can be downloaded often, but may not be highly rated. Ratings provide valuable insights into user satisfaction, which often reflects the perceived quality and value of an app. Therefore, we hypothesize revenue models that prioritize short-term gains may achieve high download counts but could negatively affect ratings if users feel misled or dissatisfied.

The main draw of a freemium model is to attract users, and have them update to a paid version [@kumar2014]. However, as @kumar2014 points out, this can be a double-edged sword. Too few features, and it may not be attractive to users. Too many features, and the users will not update. This leads to the following hypothesis.

*H2a: Apps that require the user to pay to unlock features (level 2, 3, and 4) will tend to have lower ratings than the version that requires payment upfront (level 5).*

The majority of the apps are free-to-use [@djaruma2023]. However, this means there might be more difference in quality between these apps, as the barrier to downloading is lower for free apps than paid or freemium apps [@mileros2024]. Therefore, we postulate the following.

*H2b: Apps that allow the user to have free access to all features (level 0 and 1) will have more variance in their rating, as quality can vary for free-to-access apps.*

In the same vein as H2a, users have more realistic expectations of paid apps compared to apps that require you to unlock features [@kumar2014]. Therefore, more users downloading premium apps will be satisfied with their purchase, leading to less variance. Thus, the following should follow from our data.

*H2c: Fully premium apps (level 5) and premium version of level 2 will have less variance in their ratings, while all other levels will have more.*

While popularity and ratings are distinct measures of success, they are inherently connected. Revenue models that increase downloads can also shape user expectations, which in turn influence ratings. For example, level 1 apps may dominate in terms of downloads (H1a) but face fluctuating ratings (H2c) due to quality variation. Similarly, level 2 apps may achieve high download counts for their free versions (H1c), but the gap between free and paid features could drive dissatisfaction (H2a).

### Revenue Estimation {#sec-revenue-estimation}

<!-- Dit stuk kan later ook nog verschoven worden naar de discussie als dat beter is voor de flow. -Noa -->

It is important to point out downloads and ratings likely do not directly correlate to the actual revenue of an app. The revenue of apps "premium" apps that require an upfront payment, the revenue is relatively simple to track and compare. However, for apps that rely on advertisement, in-app purchases and/or selling market information, this is harder to track.

For apps that solely on advertisement, time retention can be a good measure of revenue [@ross2018]. However, this only works if the app solely relies on ads. An example of this given by @djaruma2023 is TikTok: this app relies not only on advertisement, but also on users purchasing products through its shop. Therefore, using solely the time retention would not accurately capture the revenue of an app with both revenue streams. Furthermore, the selling of user data is usually not publicized, meaning it is not possible to know the revenue from this.

Unfortunately, our data only contains the price of "premium" app versions. The data does not include any details regarding in-app purchases nor time-retention. Because of this lack of sufficient data, solely downloads and ratings will be taken into account as indicators of success.

<!-- Officieel mag je dus maar 3 hypothesen, maar ik heb ze onderverdeeld. Zou dit mogen? -Noa -->

# Methods and Data <!-- 1,000-1,200 words -->

```{=html}
<!--

Detailed description of the dataset, clear explanation of variable translation.
Proper use of statistical methods, with careful consideration of assumptions and appropriate handling of violations.

Content: Describe the dataset(s) used, explain variable selection and translation, and provide a detailed explanation of the statistical methods applied. Justify the methodological approach and handle assumptions rigorously.
Key Elements:
Dataset description.
Explanation of variable selection.
Statistical methods and justification.
Handling of assumptions.
-->
```

In this section, we will discuss the dataset and methods used to test the hypotheses outlined in the previous section. The focus lies on providing a comprehensive description of the dataset, including its structure and the variables it contains, followed by an explanation of the variable selection process. Additionally, we outline the statistical methods applied and discuss how assumptions, such as missing values and potential biases, were addressed to ensure the robustness of our analysis.

## Dataset Description

<!--Omschrijf de data: hoeveel instances, welke variables, waar gaat de data over?-->

The dataset used in this research comprises 1,016,666 instances and 27 variables, offering a comprehensive overview of mobile applications across various revenue models. Each instance corresponds to a single app, capturing details about its characteristics, user engagement, and monetization strategies. Key variables include the app's unique identifier (my_app_id), the number of downloads (num_downloads), the average rating (rating_app), and the number of ratings received (nb_rating). These variables provide critical insights into app performance metrics.

Additional variables include pricing details (price_gplay), information about in-app purchases (in_app), and whether the app contains advertisements (has_ads). Other attributes, such as content ratings (content_rating_app) and metadata about the app developer (developer_name), further enhance the dataset’s richness by adding contextual information.

Several variables, such as whats_new (completely null) and in_app_product (89.57% null), were excluded from the analysis due to their high proportions of missing data. Conversely, variables with minor missingness (e.g., date_published, privacy_policy) were retained after appropriate preprocessing. This curated dataset is the foundation for examining monetization strategies and their relationship to app performance metrics like downloads and user ratings.

## Variable Selection

```{=html}
<!-- Welke variabelen gebruiken wij? Welke hebben we eruit gehaald? (Hierover uitbreiden in Handeling of Assumptions).

Hoe definiëren we de 5 levels?-->
```

The analysis focuses on a subset of 13 variables selected from the dataset, as shown in Table 2 below. These variables were chosen for their relevance to our research questions, capturing information about app characteristics, user engagement, and monetization strategies.

<!-- Table 2: Selected Variables for Analysis -->

| **Variable Name** | **Description** |
|-------------------------|-----------------------------------------------|
| `my_app_id` | Unique identifier for each app. |
| `num_downloads` | Number of downloads for the app. Key indicator of app success. |
| `rating_app` | Average user rating. Measures user satisfaction. |
| `nb_rating` | Number of ratings received. Reflects user engagement. |
| `price_gplay` | Price of the app. Used to differentiate free vs premium apps. |
| `in_app` | Boolean indicating whether the app has in-app purchases. |
| `has_ads` | Boolean indicating whether the app includes advertisements. |
| `content_rating_app` | Content rating of the app (e.g., Everyone, Teen). |
| `categ_app` | App category (e.g., Productivity, Games). Groups apps by functionality. |
| `developer_name` | Name of the app developer. Provides context on developer reputation. |
| `developer_info` | Additional metadata about the developer (e.g., location, website). |

To systematically explore monetization strategies, we classified the apps into six distinct levels based on their monetization models. These levels reflect varying approaches to generating revenue, ranging from completely free apps to fully premium paid apps.

-   **Level 0**: Apps with no monetization, offering free services without ads or in-app purchases.
-   **Level 1**: Free apps monetized solely through ads.
-   **Level 2**: Freemium model, employing both free sample apps with limited functionality (and potentially ads) and paid premium apps with full features.
-   **Level 3**: Apps combining ads and in-app purchases, monetizing through both strategies.
-   **Level 4**: Freemium apps monetized entirely through in-app purchases, removing ads for a seamless user experience.
-   **Level 5**: Fully premium paid apps, with no ads or in-app purchases, delivering a premium experience.

This classification is grounded in theoretical frameworks, such as the monetization levels proposed by @djaruma2023, and allows for a nuanced analysis of how different revenue models impact app success metrics like user ratings and downloads. Our systematic categorization facilitates a deeper understanding of the relationship between monetization strategies and app performance.

## Statistical Methods

To test our hypotheses, we employed a combination of descriptive statistics, text processing, and machine learning techniques, ensuring a rigorous approach to analyzing the dataset. Descriptive statistics were used to explore distributions and trends in key metrics such as num_downloads, rating_app, and price_gplay. Applications were categorized into six monetization levels using binary indicators (is_free, in_app, and has_ads), while preprocessing of price data facilitated the distinction between free and paid applications. These steps established a structured foundation for investigating relationships between monetization strategies and app performance.

For the paired application analysis within Level 2, we applied Term Frequency-Inverse Document Frequency (TF-IDF) vectorization combined with cosine similarity to app names, allowing us to measure textual similarity [@Widianto2023]. Logical pairings were refined through prefix matching and the identification of indicative terms like "Free" or "Pro." This process was further validated by ensuring paired apps shared the same developer, using metadata from developer_name and developer_info. While effective, this approach acknowledged potential limitations, such as ambiguity in naming conventions, which were flagged as edge cases for transparency.

To address potential biases in app ratings caused by low review counts, we calculated a Bayesian average, adjusting raw ratings by combining the global average with individual app ratings weighted by review volume [@MOYEED2005807]. This provided a more balanced measure of user satisfaction, reducing the influence of apps with disproportionately few reviews. Scatter plots and box plots were employed to visualize the relationships between monetization levels and user engagement metrics, offering valuable preliminary insights into patterns within the data. These visualizations, alongside the Bayesian adjustments, laid the groundwork for robust and interpretable results, which are elaborated in the results section.

### Handeling of Assumptions

We addressed missing values by removing rows with critical nulls, such as those in num_downloads, to maintain data integrity. Text-based variables like content_rating_app were standardized to ensure consistency. For price_gplay, currency symbols were removed to facilitate the classification of applications into free or paid categories.

Outliers in metrics like num_downloads were retained if they represented industry-leading applications, as their exclusion could skew the analysis. The use of Bayesian averages mitigated bias in rating_app due to low review counts, providing a more accurate reflection of user satisfaction. Covariance checks were conducted to ensure the absence of multicollinearity among numerical variables, thereby enhancing the reliability of correlation and regression analyses.

Some applications exhibited rare combinations of is_free, in_app, and has_ads that did not fit within the predefined monetization levels. These applications were excluded from the analysis but documented as a limitation. Edge cases in level 2 application pairing were flagged for potential mismatches due to naming ambiguities, ensuring transparency in the classification process.

These methodologies facilitated a systematic and accurate exploration of monetization models and their impact on application performance.

# Results <!-- 800-1,000 words -->

In this section, we will analyze the data through tables and visualizations. These plots largely explore the data around the hypotheses and research question discussed in the previous sections. The aim of this section is to test the hypotheses.

The results aim to provide an answer to the question "*How are the six different revenue models as proposed by @djaruma2023 correlate to the success of an app?*". To do so, the six different revenue models defined by @djaruma2023. Short descriptions of these levels can be found in @tbl-levels.

In order to analyze the Google Play Store data, it was first divided into these different levels. More than 75% of all the apps belong to level 0 and 1 (see @fig-distribution-amount-apps-levels). The smallest portion of apps belongs to level 2, which included both version of the same app.

```{python}
#| echo: false
#| warning: false
#| error: false
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from IPython.display import Markdown
from tabulate import tabulate

df_level_combined = pd.read_csv('./data/google_data_levels_combined.csv', dtype={16: 'string'})
df_mapping_level_2 = pd.read_csv('./data/mapping_level_2.csv', dtype={16: 'string'})
```

```{python}
#| echo: false
#| warning: false
#| error: false
#| label: fig-distribution-amount-apps-levels
#| fig-cap: "Distribution of the amount of apps across the revenue levels"

# Assuming df_level_combined['level'] exists
level_counts = df_level_combined['level'].value_counts()
level_counts = level_counts.reindex(["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"])  # Specify the order

# Creating labels for the legend with counts and percentages
total = level_counts.sum()
labels = [f"{level} - {count} ({count / total:.1%})" for level, count in level_counts.items()]

# Plotting the pie chart
plt.figure(figsize=(3, 3))
wedges, texts = plt.pie(
    level_counts, 
    labels=None,  # Hide labels on the pie chart itself
    startangle=90, 
    colors=plt.cm.Paired.colors
)

# Adding the custom legend
plt.legend(wedges, labels, title="Levels", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

plt.show()
```

To find the success of an app, metrics like popularity, the rating and the revenue estimation of an application can be used. However, as discussed in @sec-literature-review, the revenue estimation will be disregarded due to a lack of data on this variable. The number of downloads gives us a measure of popularity, and will be used to answer hypotheses H1a through H1d. The average rating given by users will allow for evaluation of hypotheses H2a through H2d.

## Downloads {#sec-number-of-downloads}

In this section, we will venture to answer hypotheses H1a through H1d. This will be done in several subsections. Firstly, in @sec-distribution-app-downloads the distribution of the downloads will be analyzed, in order to answer hypotheses H1a and H1b. In @sec-sample-premium-apps, the differences in downloads between the sample and premium versions of level 2 will be explored to answer hypotheses H1c. Lastly, in @sec-gaming-apps the downloads of the gaming apps will be further examined in order to answer hypothesis H1d.

### Distribution of app downloads {#sec-distribution-app-downloads}

This section will venture to answer the following hypotheses.

*H1a: Apps that allow the user to have free access to all features (level 0 and 1) will have the highest amount of downloads overall.*

*H1b: The apps with the most downloads will be level 1.*

In order to find whether these hypotheses are true for this dataset, the number of downloads per revenue model were visualized (@fig-total-average-downloads-by-level). @fig-total-average-downloads-by-level-1 displays the total amount of downloads, while the @fig-total-average-downloads-by-level-2 displays the average amount of downloads.

The total number of downloads (@fig-total-average-downloads-by-level-1) and the average number of downloads (@fig-total-average-downloads-by-level-2) vary wildly for levels 0 and 1. This is largely a result of the fact that 75% of the total apps fall under these levels, as can be seen in @fig-distribution-amount-apps-levels. Thus, by looking solely at the average amount of downloads per level, it does not seem that level 0 and 1 are the most downloaded apps.

```{python}
#| label: fig-total-average-downloads-by-level
#| fig-cap: "Comparison of Total and Average Downloads by Level"
#| fig-subcap:
#|   - "Total Number of Downloads by Level"
#|   - "Average Number of Downloads by Level" 
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

df_h1b = df_level_combined.copy()

# Calculate the sum of downloads for each level
total_downloads_h1b = df_h1b.groupby('level')['num_downloads'].sum().reset_index()

# Define the order of the levels
level_order = ["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"]

# First bar chart: Total Number of Downloads
sns.barplot(
    data=total_downloads_h1b,
    x='level',
    y='num_downloads',
    hue='level',
    palette='viridis',
    dodge=False,
    order=level_order
)
plt.xlabel('Level')
plt.ylabel('Total Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.tight_layout()  # Adjust layout to avoid overlap
plt.show()

# Second bar chart: Average Number of Downloads
sns.barplot(
    data=df_h1b,
    x='level',
    y='num_downloads',
    hue='level',
    palette='viridis',
    dodge=False,
    order=level_order
)
plt.xlabel('Level')
plt.ylabel('Average Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.tight_layout()  # Adjust layout to avoid overlap
plt.show()

```

As the majority of apps fall under level 0 and 1, these do have the highest overall downloads, as shown in @fig-total-average-downloads-by-level-1. @tbl-downloads-free-access shows just how big the difference between the total downloads is. The apps that are completely free to use (level 0 and 1) have over 40 billion more downloads than the apps that are paid to some extend (levels 2 through 5).

```{python}
#| label: tbl-downloads-free-access
#| tbl-cap: "Difference Total Number of Downloads"
#| echo: false
#| warning: false
#| error: false

# Create a copy of the dataframe
df_h1a = df_level_combined.copy()

# Add the 'category' column based on conditions
df_h1a['category'] = [
    'Free all access' if level in ['0', '1'] else 'Freemium and Premium'
    for level in df_h1a['level']
]

# Calculate the sum of downloads for each category
total_downloads_h1a = df_h1a.groupby('category')['num_downloads'].sum().reset_index()

Markdown(tabulate(total_downloads_h1a, headers=total_downloads_h1a.columns))
```

@fig-distribution-app-downloads provides insights into distribution inequality. The distribution of the app downloads are highly concentrated, meaning a small proportion of the apps make up for the vast majority of the downloads. @fig-distribution-app-downloads-1 shows relatively the same inequality as @fig-distribution-app-downloads-2. This indicates a small amount of apps dominate the numbers. However, it is important to note this might not be exclusive to level 0 and 1; the other levels might exhibit similar patterns.

```{python}
#| label: fig-distribution-app-downloads
#| fig-cap: "Distribution of App Downloads (Top-Heavy Analysis)"
#| fig-subcap:
#|   - "All levels except 1"
#|   - "Level 1 Only" 
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

df_h1b = df_level_combined.copy()

# convert float to int for num_downloads
df_h1b['num_downloads'] = df_h1b['num_downloads'].astype(int)

# relevant columns
relevant_columns_h1b = ['my_app_id', 'num_downloads', 'categ_app', 'level', 'developer_name']

# filter the relevant columns
df_h1b = df_h1b[relevant_columns_h1b]

# Filter the dataframe to exclude level '1'
df_no_level_1 = df_h1b[df_h1b['level'] != '1'].copy()

# Sort the dataframe by 'num_downloads' in descending order
df_no_level_1_sorted = df_no_level_1.sort_values(by='num_downloads', ascending=False)

# Calculate the cumulative percentage of downloads
df_no_level_1_sorted['cumulative_percentage_downloads'] = (
    df_no_level_1_sorted['num_downloads'].cumsum() / df_no_level_1_sorted['num_downloads'].sum() * 100
)

# Create a Lorenz curve-style plot for all levels except '1'
plt.plot(
    range(1, len(df_no_level_1_sorted) + 1),
    df_no_level_1_sorted['cumulative_percentage_downloads'],
    label='Cumulative Downloads (All Levels Except 1)'
)
plt.plot(
    [1, len(df_no_level_1_sorted)],
    [0, 100],
    linestyle='--',
    color='gray',
    label='Equality Line'
)

# Add labels and legend
plt.xlabel('Apps (sorted by downloads)')
plt.ylabel('Cumulative Percentage of Downloads')
plt.legend()
plt.grid(True)
plt.show()


# Filter the dataframe for level '1'
df_level_1 = df_h1b[df_h1b['level'] == '1'].copy()

# Sort the dataframe by 'num_downloads' in descending order
df_level_1_sorted = df_level_1.sort_values(by='num_downloads', ascending=False)

# Calculate the cumulative percentage of downloads
df_level_1_sorted['cumulative_percentage_downloads'] = df_level_1_sorted['num_downloads'].cumsum() / df_level_1_sorted['num_downloads'].sum() * 100

# Create a Lorenz curve-style plot for level '1'
plt.plot(
    range(1, len(df_level_1_sorted) + 1),
    df_level_1_sorted['cumulative_percentage_downloads'],
    label='Cumulative Downloads (Level 1)'
)
plt.plot(
    [1, len(df_level_1_sorted)],
    [0, 100],
    linestyle='--',
    color='gray',
    label='Equality Line'
)

# Add labels and legend
plt.xlabel('Apps (sorted by downloads)')
plt.ylabel('Cumulative Percentage of Downloads')
plt.legend()
plt.grid(True)
plt.show()
```

The download range of apps in @tbl-num-downloads-by-level illustrates that level 1 dominates in terms of apps with over 1 billion downloads. Furthermore, level 0 also has a few apps with over 1 billion downloads. Level 0 has the most app downloads between 500 million and 1 billion with 18.

```{python}
#| label: tbl-num-downloads-by-level
#| tbl-cap: "Number of Downloads by Level"
#| echo: false
#| warning: false
#| error: false

downloads_across_level = df_level_combined.copy()

# Define the new bins and labels
bins = [0, 1000000, 100000000, 500000000, 1000000000, np.inf]
labels = ['0-1M', '1M-100M', '100M-500M', '500M-1B', '1B+']

# Recreate the downloads_bin column with the new bins and labels
downloads_across_level['downloads_bin'] = pd.cut(downloads_across_level['num_downloads'], bins=bins, labels=labels)

# Regroup the data by level and the new downloads_bin
grouped_updated = downloads_across_level.groupby(['level', 'downloads_bin']).size().unstack(fill_value=0)


Markdown(tabulate(grouped_updated, headers=grouped_updated.columns))
```

Taking a closer look at the apps provided by @djaruma2023 in @tbl-top-8-apps-paper. We do see that Facebook, Instagram, Spotify, Snapchat and Amazon Shopping fall under level 1.

```{python}
#| label: tbl-top-8-apps-paper
#| tbl-cap: "Top 8 Apps by Downloads (in Billions)"
#| echo: false
#| warning: false
#| error: false


df_h1b = df_h1b[df_h1b['my_app_id'].isin(['com.amazon.mShop.android.shopping', 'com.instagram.android', 'com.facebook.lite', 'com.netflix.mediaclient', 'com.snapchat.android', 'com.spotify.music', 'com.whatsapp', 'com.facebook.orca'])]

df_h1b = df_h1b[['my_app_id', 'num_downloads', 'categ_app', 'level']]

df_h1b['num_downloads'] = df_h1b['num_downloads'] / 1_000_000_000

app_mapping = {
    'com.amazon.mShop.android.shopping': 'Amazon Shopping',
    'com.instagram.android': 'Instagram',
    'com.facebook.lite': 'Facebook Lite',
    'com.netflix.mediaclient': 'Netflix',
    'com.snapchat.android': 'Snapchat',
    'com.spotify.music': 'Spotify',
    'com.whatsapp': 'WhatsApp',
    'com.facebook.orca': 'Facebook Messenger'
}

# Map app names to the 'my_app_id' column
df_h1b['app_name'] = df_h1b['my_app_id'].map(app_mapping)

# Reorder columns for better readability
df_h1b = df_h1b[['app_name', 'num_downloads', 'categ_app', 'level']]


# Rename columns as per requirement
df_h1b = df_h1b.rename(columns={
    'app_name': 'App Name',
    'num_downloads': 'Downloads (in B)',
    'level': 'Level',
    'categ_app': 'Category'
})

df_h1b.sort_values(by='Downloads (in B)', ascending=False, inplace=True)
df_h1b.reset_index(drop=True, inplace=True)
Markdown(tabulate(df_h1b, headers=df_h1b.columns))
```

To summarize these findings, free apps are downloaded more than paid apps (@tbl-downloads-free-access). However, these apps are not downloaded more on average, as can be seen in @fig-total-average-downloads-by-level-2.

This means that H1a is partially true. Apps with level 0 and 1 do have the most amount of downloads, but this does not hold true for the average amount of downloads. This can be contributed to the fact that the majority of the dataset is either level 0 (34.2%) or level 1 (47.1%) (@fig-distribution-amount-apps-levels). Therefore, the support for H1a remains inconclusive, and the hypothesis must be discarded.

The most downloaded apps do fall under level 1, as can be seen in @fig-total-average-downloads-by-level-1. Further analysis shows that there is high inequality, resulting in a small proportion of the apps accounting to a majority of the downloads (@fig-distribution-app-downloads). Furthermore, @tbl-num-downloads-by-level demonstrates that apps in level 1 are considered among the top downloaded apps. Looking at the apps provided by @djaruma2023, most social network platforms indeed fall under level 1 (see @tbl-top-8-apps-paper). Given these observations, it can be concluded that there is enough evidence to support hypothesis H1b.

### Sample and Premium Apps {#sec-sample-premium-apps}

This section will test the following hypothesis.

*H1c: For apps that utilize a sample and a premium version of the same app (level 2), the free versions of an app will have more downloads than their paid-for counterpart.*

Levels 2 (premium) and 5 have the least amount of total and average downloads, as shown in @fig-total-average-downloads-by-level. Furthermore, we also see a high disparity in average downloads between level 2 sample and premium, as shown in @fig-total-average-downloads-by-level-2.

As shown in @fig-proportion-sample-premium , just 1.1% of the downloads are attributed to premium apps within all apps in level 2. This illustrates the incredible discrepancy between these download rates.

```{python}
#| label: fig-proportion-sample-premium
#| fig-cap: "Proportion of Total Downloads: Sample vs Premium"
#| echo: false
#| warning: false
#| error: false

df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)']
df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)']
df_mapping_h1c = df_mapping_level_2.copy()

# relevant columns
relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app']
relevant_columns_mapping_h1c =  ['Sample app name',	'Premium app name']

# filter the relevant columns
df_sample_h1c = df_sample_h1c[relevant_columns_h1c]
df_premium_h1c = df_premium_h1c[relevant_columns_h1c]
df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]

# Merge mapping dataframe with sample dataframe and premium dataframe
df_mapped_h1c = (
    df_mapping_h1c
    .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})
    .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'})
)

# Calculate metrics
df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads']
df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']

# Calculating total sample and premium downloads
total_sample_downloads = df_mapped_h1c['Sample Downloads'].sum()
total_premium_downloads = df_mapped_h1c['Premium Downloads'].sum()

# Creating a new dataframe to represent the totals
summary_data_h1c = {
    "Version Type": ["Sample Downloads", "Premium Downloads"],
    "Total Downloads": [total_sample_downloads, total_premium_downloads]
}
df_summary_h1c = pd.DataFrame(summary_data_h1c)

# Creating a pie chart to show the proportion of sample vs premium downloads
fig, ax = plt.subplots(figsize=(3, 3))
ax.pie(df_summary_h1c['Total Downloads'], labels=df_summary_h1c['Version Type'], autopct='%1.1f%%', startangle=140)

plt.show()
```

High disparity is also evident in the average downloads, as shown in @tbl-premium-sample-diff. Where the average download difference is close to 500.000. With an average download ratio of nearly 27%. Meaning that about one in fourth users that download the sample app, also download the premium app.

```{python}
#| label: tbl-premium-sample-diff
#| tbl-cap: "Sample and Premium download metrics"
#| echo: false
#| warning: false
#| error: false

df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)']
df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)']
df_mapping_h1c = df_mapping_level_2.copy()

# relevant columns
relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app']
relevant_columns_mapping_h1c =  ['Sample app name',	'Premium app name']

# filter the relevant columns
df_sample_h1c = df_sample_h1c[relevant_columns_h1c]
df_premium_h1c = df_premium_h1c[relevant_columns_h1c]
df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]

# Merge mapping dataframe with sample dataframe and premium dataframe
df_mapped_h1c = (
    df_mapping_h1c
    .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})
    .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'})
)

# Calculate metrics
df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads']
df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']


# Average downloads and ratios
avg_sample_downloads = df_mapped_h1c['Sample Downloads'].mean()
avg_premium_downloads = df_mapped_h1c['Premium Downloads'].mean()
avg_download_difference = df_mapped_h1c['Download Difference'].mean()
avg_download_ratio = df_mapped_h1c['Download Ratio'].mean()

# Data for the new dataframe
summary_data_h1c = {
    "Metric": [
        "Average Sample Downloads",
        "Average Premium Downloads",
        "Average Download Difference",
        "Average Download Ratio"
    ],
    "Value": [
        avg_sample_downloads,
        avg_premium_downloads,
        avg_download_difference,
        avg_download_ratio
    ]
}

# Create the summary dataframe
df_summary_h1c = pd.DataFrame(summary_data_h1c)
Markdown(tabulate(df_summary_h1c, headers=df_summary_h1c.columns))
```

In hypothesis H1c, we claim that the sample version should have more downloads than their paid-for counterpart. From @fig-total-average-downloads-by-level and @fig-total-average-downloads-by-level-2, it is apparent there is indeed an imbalance in the download rate between these classes. By examining the proportion of the sample vs premium downloads more closely (see @fig-proportion-sample-premium), this further strengthens this argument. Additionally, the high disparity across metrics in @tbl-premium-sample-diff is even more evidence to support H1c.

Therefore, hypothesis H1c is accepted.

### Games in the Google Play Store {#sec-gaming-apps}

In this section, the following hypothesis shall be tested:

*H1d: The most downloaded apps in the gaming category will likely fall under level 3 and 4.*

As is shown in @fig-total-average-downloads-by-level, there is no major difference between total and average number of downloads in level 3 and 4. Both the total and average number of downloads of level 3 and 4 are relatively high compared to other categories. Hypothesis 1d, which concerns these 2 revenue levels, claims that many popular games fall under these 2.

According to @fig-proportion-games-total-downloads-2, 15.5% of the total apps are games. These games attribute to 26.7% of the total app downloads, as shown in @fig-proportion-games-total-downloads-1. On average, the amount of downloads for games is 98.6% higher than the average downloads of the other apps (see @tbl-avg-downloads-games).

```{python}
#| label: fig-proportion-games-total-downloads
#| fig-cap: "Proportion of Games compared to other apps"
#| fig-subcap:
#|   - "Total Downloads: Gaming vs Other Apps"
#|   - "Total Amount: Gaming vs Other Apps"
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

all_apps = df_level_combined.copy()

gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter other than gaming apps
other_apps = all_apps[~all_apps['categ_app'].isin(gaming_categories)]


df_level_combined_h1d = df_level_combined.copy()

# relevant columns
relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]

# Creating a list of categories that can be considered as part of the gaming category
gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter on games category
df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]

gaming_apps = df_level_combined_h1d.copy()

# relevant columns
relevant_columns_other_apps = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
other_apps = other_apps[relevant_columns_other_apps]

# Calculate the sum of downloads for each category
total_downloads_gaming_apps = gaming_apps['num_downloads'].sum()
total_downloads_other_apps = other_apps['num_downloads'].sum()
avg_downloads_gaming_apps = gaming_apps['num_downloads'].mean()
avg_downloads_other_apps = other_apps['num_downloads'].mean()
total_amount_gaming_apps = len(gaming_apps)
total_amount_other_apps = len(other_apps)

# Creating a new dataframe to represent the totals
summary_data = {
    "Category": ["Gaming Apps", "Other Apps"],
    "Total Downloads": [total_downloads_gaming_apps, total_downloads_other_apps],
    "Total Amount": [total_amount_gaming_apps, total_amount_other_apps],
    "Average Downloads": [avg_downloads_gaming_apps, avg_downloads_other_apps]

}
df_summary = pd.DataFrame(summary_data)

# Pie chart for Total Downloads
wedges1, texts1, autotexts1 = plt.pie(
    df_summary['Total Downloads'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140
)
plt.legend(wedges1, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9))
plt.tight_layout()
plt.show()

# Pie chart for Total Amount
wedges2, texts2, autotexts2 = plt.pie(
    df_summary['Total Amount'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140
)
plt.legend(wedges2, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9))
plt.tight_layout()
plt.show()
```

```{python}
#| label: tbl-avg-downloads-games
#| tbl-cap: "Average Downloads Games vs Other Apps"
#| echo: false
#| warning: false
#| error: false

# Combine both datasets
all_apps = pd.concat([gaming_apps, other_apps])

# Calculate averages
gaming_avg = gaming_apps['num_downloads'].mean()
other_avg = other_apps['num_downloads'].mean()
overall_avg = all_apps['num_downloads'].mean()

# Percentage difference between gaming apps and overall average
gaming_vs_baseline_difference = ((gaming_avg - overall_avg) / overall_avg) * 100

# Percentage difference between other apps and overall average
other_vs_baseline_difference = ((other_avg - overall_avg) / overall_avg) * 100

# Percentage difference between gaming apps and other apps
gaming_vs_other_difference = ((gaming_avg - other_avg) / other_avg) * 100

# Create a summary table with shorter column names
summary_table = pd.DataFrame({
    'Category': ['Gaming', 'Other', 'All'],
    'Avg Downloads': [gaming_avg, other_avg, overall_avg],
    '% Diff Gaming vs Other': [
        gaming_vs_other_difference.round(2), 
        (gaming_vs_other_difference * -1).round(2), 
        "-"  # No comparison for the baseline
    ]
})

# Round the values for better readability
summary_table = summary_table.round(2)
Markdown(tabulate(summary_table, headers=summary_table.columns))
```

Up until now, these findings suggest that games are hugely popular, regardless of their revenue level. @fig-avg-downloads-level-3-4 shows that particularly games in levels 3 and 4 accrue a lot of downloads, compared to other levels.

```{python}
#| label: fig-avg-downloads-level-3-4
#| fig-cap: "Average amount of Downloads for Gaming Apps by Level"
#| echo: false
#| warning: false
#| error: false

df_level_combined_h1d = df_level_combined.copy()

# relevant columns
relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]

# Creating a list of categories that can be considered as part of the gaming category
gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter on games category
df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]

# barplot the number of downloads for each level
sns.barplot(data=df_level_combined_h1d, x='level', y='num_downloads', palette='viridis', order=level_order)
plt.xlabel('Level')
plt.ylabel('Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.show()
```

All in all, games in the Google Play Store contribute a sizeable part of all downloads. As shown in @fig-proportion-games-total-downloads-1, it attributes to 26.7% of the total downloads. Furthermore, the average downloads of games is 98.6% more than any other apps with an average close to 0.5 million downloads (see @tbl-avg-downloads-games). In level 3 and 4, the average downloads jumps to over 1 million average downloads (see @fig-avg-downloads-level-3-4). Given these observations, it can be concluded that there is enough evidence to support hypothesis H1d.

## Ratings

In this section, we will venture to answer hypotheses H2a through H2c. To start, in @sec-quality-free-paid-apps, we will try to find fluctuations in ratings that might be by the quality in order to answer hypothesis H2a and H2b. Moreover, in @sec-variance-rating, the variance in ratings will be analyzed to test hypothesis H2c.

### Quality of Free and Paid Apps {#sec-quality-free-paid-apps}

This section of the variance of free and premium apps, will test the following hypothesis.

*H2a: Apps that require the user to pay to unlock features (level 2, 3, and 4) will tend to have lower ratings than the version that requires payment upfront (level 5).*

*H2b: Apps that allow the user to have free access to all features (level 0 and 1) will have more variance in their rating, as quality can vary for free-to-access apps.*

Hypothesis 2a suggests that the apps where users need to pay to unlock features tend to have a lower rating than apps that require payment upfront.

As shown in @fig-free-vs-paid, premium apps have a higher rating on average compared to free apps with users needing to pay to unlock features. The free apps show a greater spread in ratings.

```{python}
#| label: fig-free-vs-paid
#| fig-cap: "Boxplot of Ratings for Free and Premium Apps"
#| echo: false
#| warning: false
#| error: false

df_level_combined_h2a = df_level_combined.copy()

# Filter only levels 2, 3, 4, and 5
df_h2a = df_level_combined_h2a[df_level_combined_h2a['level'].isin(['2 (Sample)', '2 (Premium)', '3', '4', '5'])].copy()

# Filter on premium and free apps
df_h2a['category'] = np.where((df_h2a['level'] == '5') | (df_h2a['level'] == '2 (Premium)'), 'Premium apps', 'Free apps')

# relevant columns
relevant_columns_h2a = ['category', 'rating_app', 'bayesian_average']

# filter the relevant columns
df_h2a = df_h2a[relevant_columns_h2a]

# Calculating the mean rating for Free and Premium apps
mean_rating_free = df_h2a[df_h2a['category'] == 'Free apps']['rating_app'].mean()
mean_rating_premium = df_h2a[df_h2a['category'] == 'Premium apps']['rating_app'].mean()

# Calculating the mean Bayesian average for Free and Premium apps
mean_bayesian_free = df_h2a[df_h2a['category'] == 'Free apps']['bayesian_average'].mean()
mean_bayesian_premium = df_h2a[df_h2a['category'] == 'Premium apps']['bayesian_average'].mean()

# Creating a new DataFrame from these results
mean_results = pd.DataFrame({
    'Category': ['Free apps', 'Premium apps'],
    'Mean Rating': [mean_rating_free, mean_rating_premium],
    'Mean Bayesian Average': [mean_bayesian_free, mean_bayesian_premium]
})

# Combine ratings for boxplot
categories = ['Free apps', 'Premium apps']
ratings_data = [df_h2a[df_h2a['category'] == cat]['rating_app'] for cat in categories]

plt.figure(figsize=(5, 3))
plt.boxplot(ratings_data, labels=categories, patch_artist=True)
plt.ylabel('Ratings')
plt.xlabel('App Category')
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

The apps that require upfront payment receive a higher rating on average then free apps, shown in @fig-free-vs-paid. This can indicate that users perceive as being of higher quality. The greater spread of ratings for free apps, may indicate that the app quality varies more. This provides sufficient evidence in support of hypothesis H2a.

Level 0 and 1 have the highest overall downloads, as shown in @tbl-downloads-free-access by quite a margin (40 billion downloads (0.4e11)) compared to the other apps. These apps under level 0 and 1 have free access to all features. Hypothesis 2b suggests that the variance in rating between "free access to all feature apps" and "free access to not all features or paid apps" is a sign of quality disparity.

@tbl-free-access shows the variance and standard deviation between "free access to all feature apps" and "free access to not all features or paid apps". From which we can conclude that there is not a big statistical difference. Roughly, 0.02 and 0.01 difference in variance and standard deviation rating respectively.

```{python}
#| label: tbl-free-access
#| tbl-cap: "Variance (and std) difference. Between free access to all feature apps and free access to not all features or paid apps"
#| echo: false
#| warning: false
#| error: false


df_h1a = df_level_combined.copy()

# if level is 0 or 1 then new column category is 'Free apps'
df_h1a['category'] = ['Free all access' if level in ['0', '1'] else 'Freemium and Premium' for level in df_h1a['level']]

# Calculate variance and standard deviation for each category
df_stats_h1a = df_h1a.groupby('category')['rating_app'].agg(['var', 'std']).reset_index()

# Rename columns for clarity
df_stats_h1a.rename(columns={'var': 'variance in rating', 'std': 'standard deviation in rating'}, inplace=True)

Markdown(tabulate(df_stats_h1a, headers=df_stats_h1a.columns))
```

@fig-free-access visualizes variance with outliers. It shows that both categories have a similar median rating close to 4.5, with "Free/Paid not all feature apps" being slightly lower. Both categories seem to have a lot of outliers under 3, with 'free all feature apps' having more outliers in 2 and 1.

```{python}
#| label: fig-free-access
#| fig-cap: "Boxplot of Ratings by App Category"
#| echo: false
#| warning: false
#| error: false

# Step 1: Add 'category' column based on level
df_h1a = df_level_combined.copy()
df_h1a['category'] = [
    'Free all feature apps' if level in ['0', '1'] else 'Free/Paid not all feature apps' 
    for level in df_h1a['level']
]

# Step 3: Create a boxplot for ratings categorized by 'category'

# Prepare data for custom boxplot
categories = df_h1a['category'].unique()
ratings_data = [df_h1a[df_h1a['category'] == category]['rating_app'] for category in categories]

# Custom boxplot
plt.figure(figsize=(5, 3))
plt.boxplot(ratings_data, labels=categories, patch_artist=True)
plt.ylabel('Ratings')
plt.xlabel('App Category')
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

The variance and standard deviation is minimal between the two categories, as shown in @tbl-free-access . @fig-free-access illustrates that both categories receive high ratings, with significant number of outliers. These outliers can be interpreted as variability in user satisfaction. The slighty higher median in 'Free all feature apps' may imply that users prefer this over 'Free/Paid not all feature apps'. However, this is marginal and would probably require statistical validation. Thus, the evidence to suggest level 0 and 1 have more variance is inconclusive, leading to rejection of hypothesis H2b.

### Variance in Ratings {#sec-variance-rating}

This section will attempt to answer the following hypothesis regarding the variance in ratings

*H2c: Fully premium apps (level 5) and premium version of level 2 will have less variance in their ratings, while all other levels will have more.*

The variance across levels shows some major differences, as illustrated in @fig-variance-rating. However, when adjusted for total reviews using a Bayesian average rating, the differences in variance diminishes. This adjustment smooths out fluctuations, offering a more consistent representation of the ratings. For level 5, we see that the variance is one of the lowest when adjusted by Bayesian average. This difference may arise because users who are satisfied with the app tend to rate the app highly, while users who are not satisfied, tend to rate it much lower, having paid for the app.

<!-- Notably, certain levels, particularly paid apps (levels 2 Premium and 5), exhibit strong outliers. (Misschien ben ik gewoon dom, maar ik snap niet hoe dit volgt uit die figuur. Daarom heb ik het weggelaten). -->

```{python}
#| label: fig-variance-rating
#| fig-cap: "Variance of Different Attributes Grouped by Level"
#| echo: false
#| warning: false
#| error: false

variance_rating = df_level_combined.copy()

# Assuming your dataframe is named df
columns_to_calculate = ['rating_app', 'bayesian_average']
variance_specific = variance_rating.groupby('level')[columns_to_calculate].var().reset_index()

# Melting the dataframe to long format for easier plotting
variance_melted = variance_specific.melt(id_vars='level', var_name='Attribute', value_name='Variance')

plt.figure(figsize=(12, 6))
sns.barplot(data=variance_melted, x='level', y='Variance', hue='Attribute', palette='viridis')
plt.xlabel('Level')
plt.ylabel('Variance')
plt.xticks(rotation=45)
plt.legend(title='Attribute', loc='upper right')
plt.tight_layout()
plt.show()
```

@fig-var-rating-other-premium illustrates a significant difference in the variance of ratings. Premium apps tend to have a higher variance, with more outliers.

```{python}
#| label: fig-var-rating-other-premium
#| fig-cap: "Variance in Ratings for Other vs Premium Apps"
#| echo: false
#| warning: false
#| error: false


df_level_combined_h2b = df_level_combined.copy()

# Filter on level 5 and others
df_level_combined['category'] = np.where(df_level_combined['level'].isin(['2 (Premium)', '5']), 'Premium apps', 'Other apps')

# Relevant columns
relevant_columns_h2b = ['category', 'rating_app', 'bayesian_average']

# Filter the relevant columns
df_level_combined_h2b = df_level_combined[relevant_columns_h2b]

# Filtering data for Free and Premium apps
other_apps = df_level_combined_h2b[df_level_combined_h2b['category'] == 'Other apps']
premium_apps = df_level_combined_h2b[df_level_combined_h2b['category'] == 'Premium apps']

# Calculating variances for ratings and bayesian averages
other_variance_rating = other_apps['rating_app'].var()
premium_variance_rating = premium_apps['rating_app'].var()

# Creating a summary table
variance_table = pd.DataFrame({
    'Category': ['Other apps', 'Premium apps'],
    'Variance in Ratings': [other_variance_rating, premium_variance_rating]
})

Markdown(tabulate(variance_table, headers=variance_table.columns))
```

In conclusion, the variance across all levels show that level 5 has the highest variance for rating and the lowest variance for bayesian rating, as shown in @fig-variance-rating. The bayesian average seems more reliable regarding the overall app performance. The premium apps may have polarized feedback due to high user expectations. In short, this provides sufficient evidence to support hypothesis H2c.

## Conclusion

The six revenue strategies proposed by @djaruma2023 show distinct relationships with app success, balancing accessibility and user satisfaction. Free models (levels 0 and 1) dominate in popularity, achieving \~40 billion downloads, but show variable ratings. Their accessibility attracts large audiences but often struggles with quality consistency. Freemium models (levels 2, 3, and 4) show more variability in ratings, reflecting differing user expectations, yet remain popular by allowing users to try features before committing. Premium apps (level 5) achieve the highest average ratings with minimal variance, reflecting their polished quality and clear value propositions, though they trade reach for exclusivity. Each model offers trade-offs: free models maximize reach, freemium models balance accessibility and satisfaction, and premium models excel in consistent quality, appealing to smaller, selective audiences.

## Ethical Considerations

This research uses publicly available Google Play Store data without involving individual user data, ensuring privacy concerns are avoided [@tikkinen-piri2018]. However, even public data can reveal sensitive business insights, such as metrics that expose proprietary strategies. To mitigate this, we avoid singling out specific apps. The findings could influence developers, marketers, and policymakers by revealing insights into profitable monetization methods like ads or in-app purchases. While these insights can help optimize revenue strategies, they also raise ethical concerns, as they might encourage exploitative practices that prioritize profits over user experience [@mileros2024]. This underscores our dual responsibility to provide actionable insights while advocating for ethical applications of our conclusions.

# Discussion <!--500-700 words -->

This study examined the relationship between six revenue strategies and app success, measured by downloads and ratings. The findings reveal clear trade-offs among these models, offering insights into app monetization strategies.

## Reflection on the Findings

We found that free apps (Levels 0 and 1) dominate in terms of downloads. However, these apps also have higher variance in ratings, suggesting they struggle with consistent quality. While this aligns with existing literature suggesting that free apps attract a broad audience but often deliver inconsistent experiences [@mileros2024], it does raise the question of whether the amount of downloads should be the primary measure of success. Free apps may have more downloads, but without understanding the deeper dynamics of user engagement and satisfaction, these figures could be misleading. For example, apps with high ratings but fewer downloads could still represent significant success in specific niches.

The finding that freemium models (Levels 2 and 3) strike a balance between accessibility and profitability is promising, as it suggests a flexible approach that could cater to both casual users and those willing to pay for premium features. As noted in previous research [@kumar2014], user retention and monetization are deeply interconnected in freemium models. This issue could explain why some freemium apps fail to reach their full potential despite high download numbers. Furthermore, we concluded the correlation between sample and premium ratings is likely due to the app quality both versions. But, this does on take into account the influence of other factors such as app category and external marketing efforts [@stocchi2022] on the ratings of the app.

The strong correlation found between premium apps (Level 5) and higher ratings aligns with the assumption that users expect a higher level of quality from paid apps. However, the trade-off here is the limited reach of premium apps, as shown by their lower download numbers. This finding suggests that while premium apps may offer superior experiences, their market appeal is often restricted by their pricing structure. It raises the issue of how to balance quality with accessibility in a market where competition is fierce, and user expectations are high.

This finding aligns with the broader literature on optimal distinctiveness, which explores how firms should manage the balance between conformity and differentiation in order to achieve superior performance [@Zhao2018]. On the one hand, products need to conform to category norms to build legitimacy, but on the other hand, they should differ enough to avoid intense competition. The study by [@vanangeren2022] further extends this line of inquiry by considering how the relationship between differentiation and performance varies based on the product’s revenue model. For premium apps, moderate differentiation appears to be an optimal strategy, allowing for both quality perception and enough market fit, but with the trade-off of a smaller, more specific user base.

## Limitations

Several limitations must be acknowledged. Downloads do not necessarily indicate revenue for freemium models [@djaruma2023]. The time the user spends on an app and the purchases made within this app [@ross2018] are better measures of the revenue for freemium applications.

Moreover, the data used for this project was collected before the launch of Tiktok, the social media platform with over 900 million users worldwide [@Ceci2024TikTokUsers]. As is mentioned in Section @sec-revenue-estimation, Tiktok has a business model that relies more on purchases through their online shop than solely user retention, making it different from other social media platforms. The inclusion of TikTok might have lead to different results when analyzing the amount of downloads, particularly level 3.

Causality is another limitation. While correlations were observed between revenue models, downloads, and ratings, confounding factors may be at play. Variables such as marketing efforts, app category, and regional preferences could influence success. Consequently, the findings should not be interpreted as direct causal relationships.

## Practical Implications for Businesses

For app developers, these findings offer valuable guidance. Selecting a revenue model should align with the app's target audience and objectives. Free models are ideal for maximizing reach, but consistent quality control is crucial. Freemium models provide flexibility, catering to diverse user preferences while driving profitability through in-app purchases. Premium models are suited for niche markets with high user expectations but require substantial upfront investment in quality.

Businesses must avoid over-reliance on these results, as they only reflect correlations. Nonetheless, revenue strategies should consider these trade-offs, balancing user satisfaction and profitability.

## Future Research Directions

Future studies could address limitations by incorporating datasets from more recent app markets, including platforms like TikTok. Further exploration of hypotheses that were not supported, such as H2b, could provide deeper insights into rating variance. Expanding the analysis to include additional metrics, such as user retention and in-app purchases, would enhance the understanding of revenue models' impact on success.

Ultimately, app monetization is a dynamic field. Ongoing research is essential to keep pace with evolving user preferences and technological advancements. By building on these findings, future work can contribute to more nuanced strategies for app success.

# References

::: {#refs}
:::
