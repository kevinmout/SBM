---
--- title: "**The Economics of App Success: How Revenue Streams Influence Downloads and User Ratings**" subtitle: "Group Assignment - Strategy and Business Models" author: "Group 5" date: "November 28, 2024" date-format: DD/MM/YYYY # Set date format to long format:    pdf: #Output pdf     documentclass: article     number-sections: true     toc: true #table of contents     toc-title: Contents #name table of contents     papersize: a4     fontsize: 12pt     fontfamily: mathptmx     geometry:       - top=25mm #top margin       - left=25mm #left margin     pdf-engine: pdflatex     cap-location: bottom # Set table caption location to bottom     include-in-header:        - text: |           \usepackage{graphicx}     include-before-body:       - text: |           \vspace{2em}           \begin{center}             \includegraphics[width=0.3\textwidth]{figures/jads.png}           \end{center}           \vspace{3em}           \newpage bibliography: references.bib bibliographystyle: apa execute:    enabled: true jupyter: python3 ---
bibliography: references.bib
---

<!-- horizontal line -->

\newpage

# Introduction <!-- 800-1,000 words -->

<!-- Content: Introduce the topic and explain its relevance in both academic and practical contexts. Justify the research gap and formulate a clear and insightful research question.  Key Elements: Background of the topic. Identification of the research gap. Relevance to current business practices. Research question. -->

With the every-growing popularity of cellphones [@charted2023], the popularity of mobile applications is also steadily increasing. In 2024, mobile applications are estimated to generate over \$900 billion in revenue [@global2019]. Generally, mobile applications ('*apps*' from here on) tend to be categorized in three different categories [@roma2016]. Paid apps are the most transparent; they revenue is based on an up-front purchase by the user. Free apps, on the other hand, require no purchase by the user at any stage. According to @roma2016, these apps make their revenue from deals with third-parties, either through advertisement or other purposes such as market information.

Finally, freemium apps are, as the name suggests, a middle-ground between free and premium. Users get access to a basic version of the application first and can unlock more features through an in-app payment [@kumar2014]. Of these three revenue models, freemium is the most commonly used and the most [@salehudin2021] and leads to more downloads as well as revenue [@liu2014].

## Academic Background

<!-- Kort samengevat: Wat is de wetenschappelijke consensus over dit topic? Dit wordt verder uitgediept in de Theory and Hypothesis sectie.-->

Most research uses these three established categories—paid, freemium, and free—when discussing revenue models for apps. However, by limiting the discussion to these three terms, nuances within these categories might be missed.

In a review paper from 2023 [@djaruma2023], different levels of monetization are suggested based on previous literature. These levels provide a clear framework for the revenue models of mobile apps, and are briefly summarized in @tbl-levels.

| Strategy                                           | Description                                                                                                                      |
|-----------------------|-------------------------------------------------|
| Level 5: Premium                                   | Pay to use the application. This either happens up-front, or after a trial period.                                               |
| Level 4: Semi-premium                              | Use a limited number of features for free. Unlock the app with all features through an in-app purchase.                          |
| Level 3: In-app advertisement and in-app purchases | Free application with ads, encouraging users to remove ads or to make in-app purchases.                                          |
| Level 2: Sample and premium                        | Two different versions of the same app. One is a version with limit features and/or ads. The other version is a premium version. |
| Level 1: In-app advertisement                      | Only one version of the app, with only ads and no in-app purchases.                                                              |
| Level 0: Free                                      | The app has no monetization. However, money can still be made through selling user information.                                  |

: Six levels of monetization for apps {#tbl-levels}

The monetization levels as shown in @tbl-levels are not meant to illustrate the revenue a firm will earn. It is meant to show how much customers may engage in paying for features or services at different levels.

Level 0 is an app that is completely free to use. This requires no payment nor ads, but may still make revenue through selling user data. This risks both ethical pitfalls, as well as scrutiny from customers [@djaruma2023].

Level 1 is an app that requires no user payment, and only makes revenue through ads. These may also make revenue by selling user information. Large social media apps such as Facebook and Instagram fall in this category [@djaruma2023].

Level 2 allows the user to purchase either a free or premium version. The free app has limit features; if the user wants to experience the app in full, they will have to purchase the premium version. However, this does run the risk of 'cannibalization', wherein users never upgrade to the premium version. Therefore, it is of the utmost importance to find the right amount of features to include in the free version [@djaruma2023].

Level 3 combines advertisement and purchases. Many pay-to-win games use this strategy [@nieborg2016]: users can sit through ads and wait a long time for certain rewards, or they can pay for immediate rewards.

Level 4 is similar to level 2: a user has a free trial version, and can upgrade to a premium version. This is often seen in subscription-style apps [@chen2023].

Level 5 is a totally premium app, where a user has to pay up-front to access as features. This level requires a high-quality app, as users will not pay for an app that is not polished.

<!-- Ik heb dit expres kort gehouden, aangezien we ook nog een uitgebreidere literatuur review hebben. Maar, misschien moet dit toch nog iets langer? -Noa -->

## Societal Background

<!-- Is there any tie to practical contexts? How is this relevant to current business practices? -->

Currently, most apps utilize the freemium revenue model [@salehudin2021]. However, as discussed in @djaruma2023, there are many revenue models between completely premium and completely free. A more fine-grained classification of app revenue models beyond the traditional "paid-freemium-free" framework holds significant societal and business implications.

For society, such distinctions enhance transparency. Some monetization models, such as free or ad-filled apps, may rely on selling user information as a source of revenue [@bamberger2020]. Therefore, clearer distinctions regarding the revenue model will empower consumers to make informed choices. It may also enable policymakers to identify and regulate exploitative practices, such as manipulative microtransactions or intrusive ad models, ensuring all applications align with ethical and legal standards [@mileros2024].

For businesses, this paper should unlock more insight into the effectiveness of different revenue streams. This will allow developers to tailor monetization strategies to specific audiences. Furthermore, both consumers and regulatory bodies are growing more concerned with the privacy concerns of apps, especially ones that rely on market information [@mileros2024]. A granular understanding helps businesses adapt, aligning profitability with sustainability and ethical considerations.

<!-- Ik ben niet helemaal blij met de flow van dit stuk, ik mis een mooie conclusie. Maar, ik kan niet bedenken :(. Dit moet later toegevoegd worden -Noa. -->

## Research Gap

<!-- Kort samengevat: Wat is de relevantie? -->

In short, apps play an increasingly important role in our techno-centric society. To improve the user experience and increase profits, consideration of revenue models is key. Despite the great depth of research on this topic, literature tends to be focussed on the three big categories of paid, freemium, and free. This lack of nuance prevents us from understanding the fine-grained details that may help improve future apps.

<!-- Wat is de research gap? En wat is dus de onderzoekvraag? -->

The levels of monetization proposed by @djaruma2023 offer an opportunity to capture this nuance. However, no empirical study has yet applied their framework, as their paper was published only last year. By using this framework to examine how different revenue streams impact app popularity, this study aims to provide valuable insights into consumer preferences. Therefore, this paper seeks to answer the question: *How are the six different revenue models proposed by @djaruma2023 correlated with app success?*

<!-- Wederom: kort maar krachtig, of té kort? -Noa -->

# Theory and Hypotheses <!-- 1,000-1,200 words -->

<!--   Comprehensive coverage of relevant literature, effectively building towards the research question. Development of up to three hypotheses, clearly grounded in the theoretical framework.  Content: Review relevant literature to build a strong theoretical framework. Develop up to three hypotheses that directly connect to the theory and research question.  Key Elements: Comprehensive literature review. Explanation of key theoretical concepts. Development of hypotheses. -->

In this section, prior research into the topic of revenue streams and its correlation to success in apps will be discussed. As mentioned in the Introduction section, this paper will apply the six levels of revenue as proposed by @djaruma2023 to app data. The following section will contain a holistic overview of the existing research, as well as hypotheses that arise from this theoretical framework.

## Literature Review

According to @djaruma2023, there are six distinct revenue strategies for apps. However, it is important to point out they were not the inventors of these revenue strategies; these arose from the literature they analyzed. In the following section, we shall look at the previous research into these revenue strategies.

Firstly, biggest portion of apps are free to download. In fact, this contributes over 95% of all apps in both the Google Play Store as well as the IOS App Store [@statista2023apps]. But, this does not mean the apps do not generate revenue; they might implement advertisements, in-app purchases or sample and premium versions to still make a profit.

@sensortower2023forecast has predicted global spending on in-app advertisements will reach over 233 billion U.S. dollars in 2026. These funds are an important source of income for mobile app developers [@gao2022; @maddodi2023].

Aside from advertisements, there are two different revenue strategies to consider: in-app purchases, and a trial and premium version of the same app. Both of these are considered "freemium" in recent literature. @kumar2014 describes freemium as apps for which users get basic features for free and can update it using a payment. This can be done both through in-app payments, as well as purchasing the premium version of an app.

Another revenue strategy used in apps are in-app payments. This strategy is often used in games. More specifically, games that fall in the "pay-to-win" category [@nieborg2016]. These games often require the user to wait or watch advertisements, which they can circumvent by paying. Some games also allow users to buy special features, such as the look of their avatar or special powers. Nonetheless, while in-app purchases are a proven revenue strategy, it does come with risks. Notably, in-app payments are also prone to security risks, as it requires more complex interactions and involves more participants than traditional payment [@yang2019]. Therefore, developers need to make sure their payment methods are secure before launching an app with this revenue strategy.

In-app purchases are not the only solution for offering freemium services. A different method is offering two different versions: a free one, and a paid one. The free version often has limit features combined with ads, meaning you make a profit by advertisements [@appel2020]. This is combined with the revenue of the premium version.

To answer the question "*How are the six different revenue models as proposed by @djaruma2023 correlate to the success of an app?*", we must first define what constitutes to success. In this paper, success will be defined by a couple of factors: popularity, rating, and estimated revenue.

### Popularity

The popularity of an app can be measured by the number of downloads. It is important to note the popularity of an app is complex, and is not solely dependent on the chosen revenue model. Other features, such as whether an app is featured on charts, whether it has frequent updates, and word-of-mouth awareness, will also impact the popularity of an app [@aydingokgoz2021]. However, despite these other variables, to versions of the same app will still have drastically different performances with different revenue streams [@liu2014].

Building on this, we hypothesize that revenue models associated with fewer barriers to entry will drive higher downloads overall, but the impact of these models may vary by app type and market context.

*H1a: Apps that allow the user to have free access to all features (level 0 and 1) will have the highest amount of downloads overall.*

As @djaruma2023 has shown, the most highly ranked apps are level 1. These apps are the big social media platforms such as Instagram and Facebook. Therefore, we expect this to be reflected within our data and the following to be true.

*H1b: The apps with the most downloads will be level 1.*

Freemium apps can be implemented with either in-app purchases or different versions. For the latter, we expect more downloads to be generated by the free app, than its premium counterpart. As demonstrated by @liu2012freemium, users tend to download the trial version before comitting to a premium version. Thus, the following is likely to be true.

*H1c: For apps that utilize a sample and a premium version of the same app (level 2), the free versions of an app will have more downloads than their paid-for counterpart.*

Finally, many games use a pay-to-win mechanism [@nieborg2016]. Therefore, we expect these in-app payment constructions to be used for most highly downloaded games.

*H1d: The most downloaded apps in the gaming category will likely fall under level 3 and 4.*

### Rating

The downloads of an app are not everything. An app can be downloaded often, but may not be highly rated. Ratings provide valuable insights into user satisfaction, which often reflects the perceived quality and value of an app. Therefore, we hypothesize revenue models that prioritize short-term gains may achieve high download counts but could negatively affect ratings if users feel misled or dissatisfied.

The main draw of a freemium model is to attract users, and have them update to a paid version [@kumar2014]. However, as @kumar2014 points out, this can be a double-edged sword. Too few features, and it may not be attractive to users. Too many features, and the users will not update. This leads to the following hypothesis.

*H2a: Apps that require the user to pay to unlock features (level 2, 3, and 4) will tend to have lower ratings than the version that requires payment upfront (level 5).*

The majority of the apps are free-to-use [@djaruma2023]. However, this means there might be more difference in quality between these apps, as the barrier to downloading is lower for free apps than paid or freemium apps [@mileros2024]. Therefore, we postulate the following.

*H2b: Apps that allow the user to have free access to all features (level 0 and 1) will have more variance in their rating, as quality can vary for free-to-access apps.*

In the same vein as H2a, users have more realistic expectations of paid apps compared to apps that require you to unlock features [@kumar2014]. Therefore, more users downloading premium apps will be satisfied with their purchase, leading to less variance. Thus, the following should follow from our data.

*H2c: Fully premium apps (level 5) and premium version of level 2 will have less variance in their ratings, while all other levels will have more.*

As was shown by @liu2012freemium, apps with a high rating for the premium version of an app, tended to also have a higher rating for the free counterpart. The study done by @liu2012freemium only utilized the most popular apps in the Google Play Store, but a similar pattern should emerge from our dataset. Therefore, we postulate the following.

*H2d: For apps that utilize a sample and a premium version of the same app (level 2), the rating of the paid-for version is positively associated with the rating of the free version of the same app.*

While popularity and ratings are distinct measures of success, they are inherently connected. Revenue models that increase downloads can also shape user expectations, which in turn influence ratings. For example, level 1 apps may dominate in terms of downloads (H1a) but face fluctuating ratings (H2c) due to quality variation. Similarly, level 2 apps may achieve high download counts for their free versions (H1c), but the gap between free and paid features could drive dissatisfaction (H2a).

### Revenue Estimation {#revenue-estimation}

<!-- Dit stuk kan later ook nog verschoven worden naar de discussie als dat beter is voor de flow. -Noa -->

It is important to point out downloads and ratings likely do not directly correlate to the actual revenue of an app. The revenue of apps "premium" apps that require an upfront payment, the revenue is relatively simple to track and compare. However, for apps that rely on advertisement, in-app purchases and/or selling market information, this is harder to track.

For apps that solely on advertisement, time retention can be a good measure of revenue [@ross2018]. However, this only works if the app solely relies on ads. An example of this given by @djaruma2023 is TikTok: this app relies not only on advertisement, but also on users purchasing products through its shop. Therefore, using solely the time retention would not accurately capture the revenue of an app with both revenue streams. Furthermore, the selling of user data is usually not publicized, meaning it is not possible to know the revenue from this.

Unfortunately, our data only contains the price of "premium" app versions. The data does not include any details regarding in-app purchases nor time-retention. Because of this lack of sufficient data, solely downloads and ratings will be taken into account as indicators of success.

<!-- Officieel mag je dus maar 3 hypothesen, maar ik heb ze onderverdeeld. Zou dit mogen? -Noa -->

# Methods and Data <!-- 1,000-1,200 words -->

```{=html}
<!--

Detailed description of the dataset, clear explanation of variable translation.
Proper use of statistical methods, with careful consideration of assumptions and appropriate handling of violations.

Content: Describe the dataset(s) used, explain variable selection and translation, and provide a detailed explanation of the statistical methods applied. Justify the methodological approach and handle assumptions rigorously.
Key Elements:
Dataset description.
Explanation of variable selection.
Statistical methods and justification.
Handling of assumptions.
-->
```
In this section, we will discuss the dataset and methods used to test the hypotheses outlined in the previous section. The focus lies on providing a comprehensive description of the dataset, including its structure and the variables it contains, followed by an explanation of the variable selection process. Additionally, we outline the statistical methods applied and discuss how assumptions, such as missing values and potential biases, were addressed to ensure the robustness of our analysis.

## Dataset Description

<!--Omschrijf de data: hoeveel instances, welke variables, waar gaat de data over?-->

The dataset used in this research comprises 1,016,666 instances and 27 variables, offering a comprehensive overview of mobile applications across various revenue models. Each instance corresponds to a single app, capturing details about its characteristics, user engagement, and monetization strategies. Key variables include the app's unique identifier (my_app_id), the number of downloads (num_downloads), the average rating (rating_app), and the number of ratings received (nb_rating). These variables provide critical insights into app performance metrics.

Additional variables include pricing details (price_gplay), information about in-app purchases (in_app), and whether the app contains advertisements (has_ads). Other attributes, such as content ratings (content_rating_app) and metadata about the app developer (developer_name), further enhance the dataset’s richness by adding contextual information.

Several variables, such as whats_new (completely null) and in_app_product (89.57% null), were excluded from the analysis due to their high proportions of missing data. Conversely, variables with minor missingness (e.g., date_published, privacy_policy) were retained after appropriate preprocessing. This curated dataset is the foundation for examining monetization strategies and their relationship to app performance metrics like downloads and user ratings.

## Variable Selection

```{=html}
<!-- Welke variabelen gebruiken wij? Welke hebben we eruit gehaald? (Hierover uitbreiden in Handeling of Assumptions).

Hoe definiëren we de 5 levels?-->
```
The analysis focuses on a subset of 13 variables selected from the dataset, as shown in Table 2 below. These variables were chosen for their relevance to our research questions, capturing information about app characteristics, user engagement, and monetization strategies.

<!-- Table 2: Selected Variables for Analysis -->

| **Variable Name**    | **Description**                                                         |
|------------------------|-----------------------------------------------|
| `my_app_id`          | Unique identifier for each app.                                         |
| `num_downloads`      | Number of downloads for the app. Key indicator of app success.          |
| `rating_app`         | Average user rating. Measures user satisfaction.                        |
| `nb_rating`          | Number of ratings received. Reflects user engagement.                   |
| `price_gplay`        | Price of the app. Used to differentiate free vs premium apps.           |
| `in_app`             | Boolean indicating whether the app has in-app purchases.                |
| `has_ads`            | Boolean indicating whether the app includes advertisements.             |
| `content_rating_app` | Content rating of the app (e.g., Everyone, Teen).                       |
| `categ_app`          | App category (e.g., Productivity, Games). Groups apps by functionality. |
| `developer_name`     | Name of the app developer. Provides context on developer reputation.    |
| `developer_info`     | Additional metadata about the developer (e.g., location, website).      |

To systematically explore monetization strategies, we classified the apps into six distinct levels based on their monetization models. These levels reflect varying approaches to generating revenue, ranging from completely free apps to fully premium paid apps.

-   **Level 0**: Apps with no monetization, offering free services without ads or in-app purchases.
-   **Level 1**: Free apps monetized solely through ads.
-   **Level 2**: Freemium model, employing both free sample apps with limited functionality (and potentially ads) and paid premium apps with full features.
-   **Level 3**: Apps combining ads and in-app purchases, monetizing through both strategies.
-   **Level 4**: Freemium apps monetized entirely through in-app purchases, removing ads for a seamless user experience.
-   **Level 5**: Fully premium paid apps, with no ads or in-app purchases, delivering a premium experience.

This classification is grounded in theoretical frameworks, such as the monetization levels proposed by @djaruma2023, and allows for a nuanced analysis of how different revenue models impact app success metrics like user ratings and downloads. Our systematic categorization facilitates a deeper understanding of the relationship between monetization strategies and app performance.

## Statistical Methods

To test our hypotheses, we employed a combination of descriptive statistics, text processing, and machine learning techniques, ensuring a rigorous approach to analyzing the dataset. Descriptive statistics were used to explore distributions and trends in key metrics such as num_downloads, rating_app, and price_gplay. Applications were categorized into six monetization levels using binary indicators (is_free, in_app, and has_ads), while preprocessing of price data facilitated the distinction between free and paid applications. These steps established a structured foundation for investigating relationships between monetization strategies and app performance.

For the paired application analysis within Level 2, we applied Term Frequency-Inverse Document Frequency (TF-IDF) vectorization combined with cosine similarity to app names, allowing us to measure textual similarity [@Widianto2023]. Logical pairings were refined through prefix matching and the identification of indicative terms like "Free" or "Pro." This process was further validated by ensuring paired apps shared the same developer, using metadata from developer_name and developer_info. While effective, this approach acknowledged potential limitations, such as ambiguity in naming conventions, which were flagged as edge cases for transparency.

To address potential biases in app ratings caused by low review counts, we calculated a Bayesian average, adjusting raw ratings by combining the global average with individual app ratings weighted by review volume [@MOYEED2005807]. This provided a more balanced measure of user satisfaction, reducing the influence of apps with disproportionately few reviews. Scatter plots and box plots were employed to visualize the relationships between monetization levels and user engagement metrics, offering valuable preliminary insights into patterns within the data. These visualizations, alongside the Bayesian adjustments, laid the groundwork for robust and interpretable results, which are elaborated in the results section.

### Handeling of Assumptions

We addressed missing values by removing rows with critical nulls, such as those in num_downloads, to maintain data integrity. Text-based variables like content_rating_app were standardized to ensure consistency. For price_gplay, currency symbols were removed to facilitate the classification of applications into free or paid categories.

Outliers in metrics like num_downloads were retained if they represented industry-leading applications, as their exclusion could skew the analysis. The use of Bayesian averages mitigated bias in rating_app due to low review counts, providing a more accurate reflection of user satisfaction. Covariance checks were conducted to ensure the absence of multicollinearity among numerical variables, thereby enhancing the reliability of correlation and regression analyses.

Some applications exhibited rare combinations of is_free, in_app, and has_ads that did not fit within the predefined monetization levels. These applications were excluded from the analysis but documented as a limitation. Edge cases in level 2 application pairing were flagged for potential mismatches due to naming ambiguities, ensuring transparency in the classification process.

These methodologies facilitated a systematic and accurate exploration of monetization models and their impact on application performance.

# Results <!-- 800-1,000 words -->

<!-- Clear presentation of results, including descriptive statistics and relevant tables/visualizations. Effective interpretation of results, linked to hypotheses and research question.  Content: Present the results clearly, including descriptive statistics, tables, and visualizations. Interpret the results and link them back to the hypotheses and research question.  Key Elements: Clear presentation of results. Descriptive statistics. Visualizations (e.g., graphs, charts). Interpretation of results.  !! Voor volle punten, zorg dat je terug refereert naar de hypothesen !! -->

In this section, we will analyze the data through tables and visualizations. These plots largely explore the data around the hypotheses and research question discussed in the previous sections. The aim of this section is to test the hypotheses.

The results aim to provide an answer to the question "*How are the six different revenue models as proposed by @djaruma2023 correlate to the success of an app?*". To do so, the six different revenue models defined by @djaruma2023. Short descriptions of these levels can be found in @tbl-levels.

In order to analyze the Google Play Store data, it was first divided into these different levels. More than 75% of all the apps belong to level 0 and 1 (see @fig-distribution-amount-apps-levels). The smallest portion of apps belongs to level 2, which included both version of the same app.

`{python} #| echo: false #| warning: false #| error: false import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import numpy as np from IPython.display import Markdown from tabulate import tabulate  df_level_combined = pd.read_csv('./data/google_data_levels_combined.csv', dtype={16: 'string'}) df_mapping_level_2 = pd.read_csv('./data/mapping_level_2.csv', dtype={16: 'string'})}`

`{python} #| echo: false #| warning: false #| error: false #| label: fig-distribution-amount-apps-levels #| fig-cap: "Distribution of the amount of apps across the revenue levels"  # Assuming df_level_combined['level'] exists level_counts = df_level_combined['level'].value_counts() level_counts = level_counts.reindex(["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"])  # Specify the order  # Creating labels for the legend with counts and percentages total = level_counts.sum() labels = [f"{level} - {count} ({count / total:.1%})" for level, count in level_counts.items()]  # Plotting the pie chart plt.figure(figsize=(3, 3)) wedges, texts = plt.pie(     level_counts,      labels=None,  # Hide labels on the pie chart itself     startangle=90,      colors=plt.cm.Paired.colors )  # Adding the custom legend plt.legend(wedges, labels, title="Levels", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))  plt.show()}`

To find the success of an app, metrics like popularity, the rating and the revenue estimation of an application can be used. However, as discussed in @sec-literature-review, the revenue estimation will be disregarded due to a lack of data on this variable. The number of dowloads gives us a measure of popularity, and will be used to answer hypotheses H1a through H1d. The average rating given by users will allow for evaluation of hypotheses H2a through H2d.

## Downloads {#sec-number-of-downloads}

In this section, we will venture to answer hypotheses H1a through H1d. This will be done in several subsections. Firstly, in @sec-distribution-app-downloads the distribution of the downloads will be analyzed, in order to answer hypotheses H1a and H1b. In @sec-sample-premium-apps, the differences in downloads between the sample and premium versions of level 2 will be explored to answer hypotheses H1c. Lastly, in @sec-gaming-apps the downloads of the gaming apps will be further examined in order to answer hypothesis H1d.

### Distribution of app downloads {#sec-distribution-app-downloads}

This section will venture to answer the following hypotheses.

*H1a: Apps that allow the user to have free access to all features (level 0 and 1) will have the highest amount of downloads overall.*

*H1b: The apps with the most downloads will be level 1.*

In order to find whether these hypotheses are true for this dataset, the number of downloads per revenue model were visualized (@fig-total-average-downloads-by-level). @fig-total-average-downloads-by-level-1 displays the total amount of downloads, while the @fig-total-average-downloads-by-level-2 displays the average amount of downloads.

The total number of downloads (@fig-total-average-downloads-by-level-1) and the average number of downloads (@fig-total-average-downloads-by-level-2) vary wildly for levels 0 and 1. This is largely a result of the fact that 75% of the total apps fall under these levels, as can be seen in @fig-distribution-amount-apps-levels. Thus, by looking solely at the average amount of downloads per level, it does not seem that level 0 and 1 are the most downloaded apps.

`{python} #| label: fig-total-average-downloads-by-level #| fig-cap: "Comparison of Total and Average Downloads by Level" #| fig-subcap: #|   - "Total Number of Downloads by Level" #|   - "Average Number of Downloads by Level"  #| layout-ncol: 2 #| echo: false #| warning: false #| error: false  df_h1b = df_level_combined.copy()  # Calculate the sum of downloads for each level total_downloads_h1b = df_h1b.groupby('level')['num_downloads'].sum().reset_index()  # Define the order of the levels level_order = ["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"]  # First bar chart: Total Number of Downloads sns.barplot(     data=total_downloads_h1b,     x='level',     y='num_downloads',     hue='level',     palette='viridis',     dodge=False,     order=level_order ) plt.xlabel('Level') plt.ylabel('Total Number of Downloads') plt.xticks(rotation=90)  # Rotate x-axis labels plt.tight_layout()  # Adjust layout to avoid overlap plt.show()  # Second bar chart: Average Number of Downloads sns.barplot(     data=df_h1b,     x='level',     y='num_downloads',     hue='level',     palette='viridis',     dodge=False,     order=level_order ) plt.xlabel('Level') plt.ylabel('Average Number of Downloads') plt.xticks(rotation=90)  # Rotate x-axis labels plt.tight_layout()  # Adjust layout to avoid overlap plt.show()}`

As the majority of apps fall under level 0 and 1, these do have the highest overall downloads, as shown in @fig-total-average-downloads-by-level-1. @fig-downloads-free-access illustrates just how big the difference between the total downloads is. The apps that are completely free to use (level 0 and 1) have over 40 billion more downloads than the apps that are paid to some extend (levels 2 through 5).

`{python} #| label: fig-downloads-free-access #| fig-cap: "Difference Total Number of Downloads" #| echo: false #| warning: false #| error: false  df_h1a = df_level_combined.copy()  # if level is 0 or 1 then new column category is 'Free apps' df_h1a['category'] = ['Free all feature apps' if level in ['0', '1'] else 'Free/Paid not all feature apps' for level in df_h1a['level']]  # Calculate the sum of downloads for each category total_downloads_h1a = df_h1a.groupby('category')['num_downloads'].sum().reset_index()   # Make a bar chart  plt.figure(figsize=(5, 3)) sns.barplot(data=total_downloads_h1a, x='category', y='num_downloads', hue='category', palette='viridis', dodge=False) plt.xlabel('Category') plt.ylabel('Total Number of Downloads') plt.show()}`

@fig-distribution-app-downloads provides insights into distribution inequality. The distribution of the app downloads are highly concentrated, meaning a small proportion of the apps make up for the vast majority of the downloads. @fig-distribution-app-downloads-1 shows relatively the same inequality as @fig-distribution-app-downloads-2. This indicates a small amount of apps dominate the numbers. However, it is important to note this might not be exclusive to level 0 and 1; the other levels might exhibit similar patterns.

`{python} #| label: fig-distribution-app-downloads #| fig-cap: "Distribution of App Downloads (Top-Heavy Analysis)" #| fig-subcap: #|   - "All levels except 1" #|   - "Level 1 Only"  #| layout-ncol: 2 #| echo: false #| warning: false #| error: false  df_h1b = df_level_combined.copy()  # convert float to int for num_downloads df_h1b['num_downloads'] = df_h1b['num_downloads'].astype(int)  # relevant columns relevant_columns_h1b = ['my_app_id', 'num_downloads', 'categ_app', 'level', 'developer_name']  # filter the relevant columns df_h1b = df_h1b[relevant_columns_h1b]  # Filter the dataframe to exclude level '1' df_no_level_1 = df_h1b[df_h1b['level'] != '1'].copy()  # Sort the dataframe by 'num_downloads' in descending order df_no_level_1_sorted = df_no_level_1.sort_values(by='num_downloads', ascending=False)  # Calculate the cumulative percentage of downloads df_no_level_1_sorted['cumulative_percentage_downloads'] = (     df_no_level_1_sorted['num_downloads'].cumsum() / df_no_level_1_sorted['num_downloads'].sum() * 100 )  # Create a Lorenz curve-style plot for all levels except '1' plt.plot(     range(1, len(df_no_level_1_sorted) + 1),     df_no_level_1_sorted['cumulative_percentage_downloads'],     label='Cumulative Downloads (All Levels Except 1)' ) plt.plot(     [1, len(df_no_level_1_sorted)],     [0, 100],     linestyle='--',     color='gray',     label='Equality Line' )  # Add labels and legend plt.xlabel('Apps (sorted by downloads)') plt.ylabel('Cumulative Percentage of Downloads') plt.legend() plt.grid(True) plt.show()   # Filter the dataframe for level '1' df_level_1 = df_h1b[df_h1b['level'] == '1'].copy()  # Sort the dataframe by 'num_downloads' in descending order df_level_1_sorted = df_level_1.sort_values(by='num_downloads', ascending=False)  # Calculate the cumulative percentage of downloads df_level_1_sorted['cumulative_percentage_downloads'] = df_level_1_sorted['num_downloads'].cumsum() / df_level_1_sorted['num_downloads'].sum() * 100  # Create a Lorenz curve-style plot for level '1' plt.plot(     range(1, len(df_level_1_sorted) + 1),     df_level_1_sorted['cumulative_percentage_downloads'],     label='Cumulative Downloads (Level 1)' ) plt.plot(     [1, len(df_level_1_sorted)],     [0, 100],     linestyle='--',     color='gray',     label='Equality Line' )  # Add labels and legend plt.xlabel('Apps (sorted by downloads)') plt.ylabel('Cumulative Percentage of Downloads') plt.legend() plt.grid(True) plt.show()}`

The download range of apps in @fig-num-downloads-by-level-log illustrates that level 1 dominates in terms of apps with over 1 billion downloads. Furthermore, level 0 also has a few apps with over 1 billion downloads.

`{python} #| label: fig-num-downloads-by-level-log #| fig-cap: "Number of Downloads by Level (Log Scale)" #| echo: false #| warning: false #| error: false  downloads_across_level = df_level_combined.copy()  # Define the bins and labels bins = [0, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, np.inf] labels = ['0-100', '101-1k', '1k-10k', '10k-100k', '100k-1M', '1M-10M', '10M-100M', '100M-1B', '1B+']  # Create a new column 'downloads_bin' based on the number of downloads downloads_across_level['downloads_bin'] = pd.cut(downloads_across_level['num_downloads'], bins=bins, labels=labels)  # Group by 'level' and 'downloads_bin' to get the count of apps per download bin for each level grouped = downloads_across_level.groupby(['level', 'downloads_bin']).size().unstack(fill_value=0)  # Plotting the bar chart with log scale grouped.plot(kind='bar', stacked=False, figsize=(12, 8), logy=True) plt.xlabel('Level') plt.ylabel('Number of Apps (Log Scale)') plt.xticks(rotation=90) plt.legend(title='Download Range', bbox_to_anchor=(1.05, 1), loc='upper left') plt.tight_layout() plt.show()}`

The apps categories *Communication* and *Social* classify as social platforms as shown in @fig-num-downloads-1-billion. Attributing to 40% of all the apps with more than 1 billion downloads.

`{python} #| label: fig-num-downloads-1-billion #| fig-cap: "1 Billion+ Downloads in Level 1" #| echo: false #| warning: false #| error: false  downloads_across_level = df_level_combined.copy() downloads_across_level = downloads_across_level[downloads_across_level['level'] == '1'].copy()  # Add '1B Downloads' column downloads_across_level['1B Downloads'] = downloads_across_level['num_downloads'] >= 1_000_000_000  # Filter for apps with 1 billion or more downloads billion_downloads = downloads_across_level[downloads_across_level['1B Downloads'] == True]  # Preparing data billion_downloads_summary = billion_downloads['categ_app'].value_counts().reset_index() billion_downloads_summary.columns = ['Category', 'Number of Apps']  # Sort and place "Social" next to "Communication" custom_order = ['Communication', 'Social'] + [     cat for cat in billion_downloads_summary['Category'] if cat not in ['Communication', 'Social'] ] billion_downloads_summary = billion_downloads_summary.set_index('Category').loc[custom_order].reset_index()  # Data for the pie chart sizes = billion_downloads_summary['Number of Apps'] labels = billion_downloads_summary['Category']  # Creating labels for the legend with counts and percentages total_count = sum(sizes) legend_labels_with_percentages = [     f"{category} - {count} ({count / total_count:.1%})"     for category, count in zip(labels, sizes) ]  # Plotting the pie chart without percentages on the chart plt.figure(figsize=(5, 5))  # Adjust the size of the pie chart wedges, texts = plt.pie(     sizes,      labels=None,  # Hide labels on the pie chart itself     startangle=90,      colors=plt.cm.Paired(np.linspace(0, 1, len(labels)))  # Distinct colors )  # Adding the custom legend with counts and percentages plt.legend(     wedges,      legend_labels_with_percentages,      title="Categories",      loc="center left",      bbox_to_anchor=(1, 0, 0.5, 1)  # Custom legend position )  plt.tight_layout() plt.show()}`

Taking a closer look at the apps provided by @djaruma2023 in @tbl-top-8-apps-paper. We do see that Facebook, Instagram, Spotify, Snapchat and Amazon Shopping fall under level 1.

<!-- It is important to note TikTok did not exist up until 2019, so this was not included within these results. Dit heb ik verplaatst naar de discussion - Noa. -->

`{python} #| label: tbl-top-8-apps-paper #| tbl-cap: "Top 8 Apps by Downloads (in Billions)" #| echo: false #| warning: false #| error: false   df_h1b = df_h1b[df_h1b['my_app_id'].isin(['com.amazon.mShop.android.shopping', 'com.instagram.android', 'com.facebook.lite', 'com.netflix.mediaclient', 'com.snapchat.android', 'com.spotify.music', 'com.whatsapp', 'com.facebook.orca'])]  df_h1b = df_h1b[['my_app_id', 'num_downloads', 'categ_app', 'level']]  df_h1b['num_downloads'] = df_h1b['num_downloads'] / 1_000_000_000  app_mapping = {     'com.amazon.mShop.android.shopping': 'Amazon Shopping',     'com.instagram.android': 'Instagram',     'com.facebook.lite': 'Facebook Lite',     'com.netflix.mediaclient': 'Netflix',     'com.snapchat.android': 'Snapchat',     'com.spotify.music': 'Spotify',     'com.whatsapp': 'WhatsApp',     'com.facebook.orca': 'Facebook Messenger' }  # Map app names to the 'my_app_id' column df_h1b['app_name'] = df_h1b['my_app_id'].map(app_mapping)  # Reorder columns for better readability df_h1b = df_h1b[['app_name', 'num_downloads', 'categ_app', 'level']]   # Rename columns as per requirement df_h1b = df_h1b.rename(columns={     'app_name': 'App Name',     'num_downloads': 'Downloads (in B)',     'level': 'Level',     'categ_app': 'Category' })  df_h1b.sort_values(by='Downloads (in B)', ascending=False, inplace=True) df_h1b.reset_index(drop=True, inplace=True) Markdown(tabulate(df_h1b, headers=df_h1b.columns))}`

To summarize these findings, free apps are downloaded more than paid apps (@fig-downloads-free-access). However, these apps are not downloaded more on average, as can be seen in @fig-total-average-downloads-by-level-2.

This means that H1a is partially true. Apps with level 0 and 1 do have the most amount of downloads, but this does not hold true for the average amount of downloads. This can be contributed to the fact that the majority of the dataset is either level 0 (34.2%) or level 1 (47.1%) (@fig-distribution-amount-apps-levels). Therefore, the support for H1a remains inconclusive, and the hypothesis must be discarded.

The most downloaded apps do fall under level 1, as can be seen in @fig-total-average-downloads-by-level-1. Further analysis shows that there is high inequality, resulting in a small proportion of the apps accounting to a majority of the downloads (@fig-distribution-app-downloads). Furthermore, @fig-num-downloads-by-level-log demonstrates that apps in level 1 are considered among the top downloaded apps. In particular, @fig-num-downloads-1-billion shows the categories Communication and Social, which include social media platforms, have a high amount of top downloaded apps. Looking at the apps provided by @djaruma2023, most social network platforms indeed fall under level 1 (see @tbl-top-8-apps-paper). Given these observations, it can be concluded that there is enough evidence to support hypothesis H1b.

### Sample and Premium Apps {#sec-sample-premium-apps}

This section will test the following hypothesis.

*H1c: For apps that utilize a sample and a premium version of the same app (level 2), the free versions of an app will have more downloads than their paid-for counterpart.*

Levels 2 (premium) and 5 have the least amount of total and average downloads, as shown in @fig-total-average-downloads-by-level. Furthermore, we also see a high disparity in average downloads between level 2 sample and premium, as shown in @fig-total-average-downloads-by-level-2.

As shown in @fig-proportion-sample-premium , just 1.1% of the downloads are attributed to premium apps within all apps in level 2. This illustrates the incredible discrepancy between these download rates.

`{python} #| label: fig-proportion-sample-premium #| fig-cap: "Proportion of Total Downloads: Sample vs Premium" #| echo: false #| warning: false #| error: false  df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)'] df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)'] df_mapping_h1c = df_mapping_level_2.copy()  # relevant columns relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app'] relevant_columns_mapping_h1c =  ['Sample app name',  'Premium app name']  # filter the relevant columns df_sample_h1c = df_sample_h1c[relevant_columns_h1c] df_premium_h1c = df_premium_h1c[relevant_columns_h1c] df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]  # Merge mapping dataframe with sample dataframe and premium dataframe df_mapped_h1c = (     df_mapping_h1c     .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})     .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'}) )  # Calculate metrics df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads'] df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']  # Calculating total sample and premium downloads total_sample_downloads = df_mapped_h1c['Sample Downloads'].sum() total_premium_downloads = df_mapped_h1c['Premium Downloads'].sum()  # Creating a new dataframe to represent the totals summary_data_h1c = {     "Version Type": ["Sample Downloads", "Premium Downloads"],     "Total Downloads": [total_sample_downloads, total_premium_downloads] } df_summary_h1c = pd.DataFrame(summary_data_h1c)  # Creating a pie chart to show the proportion of sample vs premium downloads fig, ax = plt.subplots(figsize=(3, 3)) ax.pie(df_summary_h1c['Total Downloads'], labels=df_summary_h1c['Version Type'], autopct='%1.1f%%', startangle=140)  plt.show()}`

High disparity is also evident in the average downloads, as shown in @tbl-premium-sample-diff. Where the average download difference is close to 500.000. With an average download ratio of nearly 27%. Meaning that about one in fourth users that download the sample app, also download the premium app.

`{python} #| label: tbl-premium-sample-diff #| tbl-cap: "Sample and Premium download metrics" #| echo: false #| warning: false #| error: false  df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)'] df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)'] df_mapping_h1c = df_mapping_level_2.copy()  # relevant columns relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app'] relevant_columns_mapping_h1c =  ['Sample app name', 'Premium app name']  # filter the relevant columns df_sample_h1c = df_sample_h1c[relevant_columns_h1c] df_premium_h1c = df_premium_h1c[relevant_columns_h1c] df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]  # Merge mapping dataframe with sample dataframe and premium dataframe df_mapped_h1c = (     df_mapping_h1c     .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})     .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'}) )  # Calculate metrics df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads'] df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']   # Average downloads and ratios avg_sample_downloads = df_mapped_h1c['Sample Downloads'].mean() avg_premium_downloads = df_mapped_h1c['Premium Downloads'].mean() avg_download_difference = df_mapped_h1c['Download Difference'].mean() avg_download_ratio = df_mapped_h1c['Download Ratio'].mean()  # Data for the new dataframe summary_data_h1c = {     "Metric": [         "Average Sample Downloads",         "Average Premium Downloads",         "Average Download Difference",         "Average Download Ratio"     ],     "Value": [         avg_sample_downloads,         avg_premium_downloads,         avg_download_difference,         avg_download_ratio     ] }  # Create the summary dataframe df_summary_h1c = pd.DataFrame(summary_data_h1c) Markdown(tabulate(df_summary_h1c, headers=df_summary_h1c.columns))}`

In hypothesis H1c, we claim that the sample version should have more downloads than their paid-for counterpart. From @fig-total-average-downloads-by-level and @fig-total-average-downloads-by-level-2, it is apparent there is indeed an imbalance in the download rate between these classes. By examining the proportion of the sample vs premium downloads more closely (see @fig-proportion-sample-premium), this further strengthens this argument. Additionally, the high disparity across metrics in @tbl-premium-sample-diff is even more evidence to support H1c (see @sec-popularity).

Therefore, hypothesis H1c is accepted.

### Games in the Google Play Store {#sec-gaming-apps}

In this section, the following hypothesis shall be tested:

*H1d: The most downloaded apps in the gaming category will likely fall under level 3 and 4.*

As is shown in @fig-total-average-downloads-by-level, there is no major difference between total and average number of downloads in level 3 and 4. Both the total and average number of downloads of level 3 and 4 are relatively high compared to other categories. Hypothesis 1d, which concerns these 2 revenue levels, claims that many popular games fall under these 2.

According to @fig-proportion-games-total-downloads-2, 15.5% of the total apps are games. These games attribute to 26.7% of the total app downloads, as shown in @fig-proportion-games-total-downloads-1. On average, the amount of downloads for games is 98.6% higher than the average downloads of the other apps (see @tbl-avg-downloads-games).

`{python} #| label: fig-proportion-games-total-downloads #| fig-cap: "Proportion of Games compared to other apps" #| fig-subcap: #|   - "Total Downloads: Gaming vs Other Apps" #|   - "Total Amount: Gaming vs Other Apps" #| layout-ncol: 2 #| echo: false #| warning: false #| error: false  all_apps = df_level_combined.copy()  gaming_categories = [     "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure",      "Trivia", "Racing", "Educational", "Card", "Word", "Board",      "Casino", "Role Playing", "Strategy", "Brain Games",      "Action & Adventure", "Pretend Play" ]  # Filter other than gaming apps other_apps = all_apps[~all_apps['categ_app'].isin(gaming_categories)]   df_level_combined_h1d = df_level_combined.copy()  # relevant columns relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']  # filter the relevant columns df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]  # Creating a list of categories that can be considered as part of the gaming category gaming_categories = [     "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure",      "Trivia", "Racing", "Educational", "Card", "Word", "Board",      "Casino", "Role Playing", "Strategy", "Brain Games",      "Action & Adventure", "Pretend Play" ]  # Filter on games category df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]  gaming_apps = df_level_combined_h1d.copy()  # relevant columns relevant_columns_other_apps = ['my_app_id', 'num_downloads', 'level', 'categ_app']  # filter the relevant columns other_apps = other_apps[relevant_columns_other_apps]  # Calculate the sum of downloads for each category total_downloads_gaming_apps = gaming_apps['num_downloads'].sum() total_downloads_other_apps = other_apps['num_downloads'].sum() avg_downloads_gaming_apps = gaming_apps['num_downloads'].mean() avg_downloads_other_apps = other_apps['num_downloads'].mean() total_amount_gaming_apps = len(gaming_apps) total_amount_other_apps = len(other_apps)  # Creating a new dataframe to represent the totals summary_data = {     "Category": ["Gaming Apps", "Other Apps"],     "Total Downloads": [total_downloads_gaming_apps, total_downloads_other_apps],     "Total Amount": [total_amount_gaming_apps, total_amount_other_apps],     "Average Downloads": [avg_downloads_gaming_apps, avg_downloads_other_apps]  } df_summary = pd.DataFrame(summary_data)  # Pie chart for Total Downloads wedges1, texts1, autotexts1 = plt.pie(     df_summary['Total Downloads'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140 ) plt.legend(wedges1, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9)) plt.tight_layout() plt.show()  # Pie chart for Total Amount wedges2, texts2, autotexts2 = plt.pie(     df_summary['Total Amount'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140 ) plt.legend(wedges2, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9)) plt.tight_layout() plt.show()}`

`{python} #| label: tbl-avg-downloads-games #| tbl-cap: "Average Downloads Games vs Other Apps" #| echo: false #| warning: false #| error: false  # Combine both datasets all_apps = pd.concat([gaming_apps, other_apps])  # Calculate averages gaming_avg = gaming_apps['num_downloads'].mean() other_avg = other_apps['num_downloads'].mean() overall_avg = all_apps['num_downloads'].mean()  # Percentage difference between gaming apps and overall average gaming_vs_baseline_difference = ((gaming_avg - overall_avg) / overall_avg) * 100  # Percentage difference between other apps and overall average other_vs_baseline_difference = ((other_avg - overall_avg) / overall_avg) * 100  # Percentage difference between gaming apps and other apps gaming_vs_other_difference = ((gaming_avg - other_avg) / other_avg) * 100  # Create a summary table with shorter column names summary_table = pd.DataFrame({     'Category': ['Gaming', 'Other', 'All'],     'Avg Downloads': [gaming_avg, other_avg, overall_avg],     '% Diff Gaming vs Other': [         gaming_vs_other_difference.round(2),          (gaming_vs_other_difference * -1).round(2),          "-"  # No comparison for the baseline     ] })  # Round the values for better readability summary_table = summary_table.round(2) Markdown(tabulate(summary_table, headers=summary_table.columns))}`

Up until now, these findings suggest that games are hugely popular, regardless of their revenue level. @fig-avg-downloads-level-3-4 shows that particularly games in levels 3 and 4 accrue a lot of downloads, compared to other levels.

`{python} #| label: fig-avg-downloads-level-3-4 #| fig-cap: "Average amount of Downloads for Gaming Apps by Level" #| echo: false #| warning: false #| error: false  df_level_combined_h1d = df_level_combined.copy()  # relevant columns relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']  # filter the relevant columns df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]  # Creating a list of categories that can be considered as part of the gaming category gaming_categories = [     "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure",      "Trivia", "Racing", "Educational", "Card", "Word", "Board",      "Casino", "Role Playing", "Strategy", "Brain Games",      "Action & Adventure", "Pretend Play" ]  # Filter on games category df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]  # barplot the number of downloads for each level sns.barplot(data=df_level_combined_h1d, x='level', y='num_downloads', palette='viridis', order=level_order) plt.xlabel('Level') plt.ylabel('Number of Downloads') plt.xticks(rotation=90)  # Rotate x-axis labels plt.show()}`

<!-- Although both levels 3 and 4 seem to have about equal downloads in @tbl-avg-downloads-games, there is a notable difference in variance. Games in level 4 seem to have more variance in downloads, compared to games in level 3. (Ik snap niet helemaal hoe tabel top 5 games deze variance verklaard, dus dit heb ik weggelaten. -Noa ) -->

The games shown in @tbl-top-5-level-3-4-games might explain, at least to some extend, why level 3 and 4 are the most downloaded revenue strategies within gaming. A lot of big names within this category use this strategy. These highly downloaded games may also explain the variance in downloads within level 3 and 4 shown in @fig-avg-downloads-level-3-4.

`{python} #| label: tbl-top-5-level-3-4-games #| tbl-cap: "Combined top 5 games of level 3 and 4" #| echo: false #| warning: false #| error: false  # Filter for level 3, sort by downloads, and pick top 5 top_apps_level_3 = df_level_combined_h1d[df_level_combined_h1d['level'] == '3'] \     .sort_values(by='num_downloads', ascending=False) \     .head(5)  app_name_mapping = {     "com.kiloo.subwaysurf": "Subway Surfers",     "com.fingersoft.hillclimb": "Hill Climb Racing",     "com.imangi.templerun2": "Temple Run 2",     "com.outfit7.mytalkingtomfree": "My Talking Tom",     "me.pou.app": "Pou" }  # Convert num_downloads to per billion top_apps_level_3['num_downloads'] = top_apps_level_3['num_downloads'] / 1_000_000_000  # Mapping the app column to their normal names top_apps_level_3['App Name'] = top_apps_level_3['my_app_id'].map(app_name_mapping)  # Rename columns as per requirement top_apps_level_3 = top_apps_level_3.rename(columns={     'num_downloads': 'Downloads (in Billions)',     'categ_app': 'Gaming Category' })  top_apps_level_3.reset_index(drop=True, inplace=True) top_apps_level_3 = top_apps_level_3[['App Name', 'Downloads (in Billions)', 'level']]  # Filter for level 4, sort by downloads, and pick top 5 top_apps_level_4 = df_level_combined_h1d[df_level_combined_h1d['level'] == '4'] \     .sort_values(by='num_downloads', ascending=False) \     .head(5)  additional_app_name_mapping = {     "com.king.candycrushsaga": "Candy Crush Saga",     "com.supercell.clashofclans": "Clash of Clans",     "com.king.petrescuesaga": "Pet Rescue Saga",     "com.king.farmheroessaga": "Farm Heroes Saga",     "com.king.candycrushsodasaga": "Candy Crush Soda Saga" }  # Convert num_downloads to per billion top_apps_level_4['num_downloads'] = top_apps_level_4['num_downloads'] / 1_000_000_000  # Mapping the app column to their normal names top_apps_level_4['App Name'] = top_apps_level_4['my_app_id'].map(additional_app_name_mapping)  # Rename columns as per requirement top_apps_level_4 = top_apps_level_4.rename(columns={     'num_downloads': 'Downloads (in Billions)',     'categ_app': 'Gaming Category' })  top_apps_level_4.reset_index(drop=True, inplace=True) top_apps_level_4 = top_apps_level_4[['App Name', 'Downloads (in Billions)','level']]  # Combine the tables combined_tables = pd.concat([top_apps_level_3, top_apps_level_4]) combined_tables.sort_values(by='Downloads (in Billions)', ascending=False, inplace=True) combined_tables.reset_index(drop=True, inplace=True) Markdown(tabulate(combined_tables, headers=combined_tables.columns))}`

All in all, games in the Google Play Store contribute a sizeable part of all downloads. As shown in @fig-proportion-games-total-downloads-1, it attributes to 26.7% of the total downloads. Furthermore, the average downloads of games is 98.6% more than any other apps with an average close to 0.5 million downloads (see @tbl-avg-downloads-games). In level 3 and 4, the average downloads jumps to over 1 million average downloads (see @fig-avg-downloads-level-3-4). Given these observations, it can be concluded that there is enough evidence to support hypothesis H1d.

## Ratings

In this section, we will venture to answer hypotheses H2a through H2d. To start, in @sec-quality-free-paid-apps, we will try to find fluctuations in ratings that might be by the quality in order to answer hypothesis H2a and H2b. Secondly, in @sec-variance-rating, the variance in ratings will be analyzed to test hypothesis H2c. Finally, in @sec-correlation the relationship between ratings of sample apps and their premium counterparts will be examined to answer hypothesis H1d.

### Quality of Free and Paid Apps {#sec-quality-free-paid-apps}

This section of the variance of free and premium apps, will test the following hypothesis.

*H2a: Apps that require the user to pay to unlock features (level 2, 3, and 4) will tend to have lower ratings than the version that requires payment upfront (level 5).*

*H2b: Apps that allow the user to have free access to all features (level 0 and 1) will have more variance in their rating, as quality can vary for free-to-access apps.*

Hypothesis 2a suggests that the apps where users need to pay to unlock features tend to have a lower rating than apps that require payment upfront.

As shown in @fig-free-vs-paid, premium apps have a higher rating on average compared to free apps with users needing to pay to unlock features. The free apps show a greater spread in ratings.

`{python} #| label: fig-free-vs-paid #| fig-cap: "Boxplot of Ratings for Free and Premium Apps" #| echo: false #| warning: false #| error: false  df_level_combined_h2a = df_level_combined.copy()  # Filter only levels 2, 3, 4, and 5 df_h2a = df_level_combined_h2a[df_level_combined_h2a['level'].isin(['2 (Sample)', '2 (Premium)', '3', '4', '5'])].copy()  # Filter on premium and free apps df_h2a['category'] = np.where((df_h2a['level'] == '5') | (df_h2a['level'] == '2 (Premium)'), 'Premium apps', 'Free apps')  # relevant columns relevant_columns_h2a = ['category', 'rating_app', 'bayesian_average']  # filter the relevant columns df_h2a = df_h2a[relevant_columns_h2a]  # Calculating the mean rating for Free and Premium apps mean_rating_free = df_h2a[df_h2a['category'] == 'Free apps']['rating_app'].mean() mean_rating_premium = df_h2a[df_h2a['category'] == 'Premium apps']['rating_app'].mean()  # Calculating the mean Bayesian average for Free and Premium apps mean_bayesian_free = df_h2a[df_h2a['category'] == 'Free apps']['bayesian_average'].mean() mean_bayesian_premium = df_h2a[df_h2a['category'] == 'Premium apps']['bayesian_average'].mean()  # Creating a new DataFrame from these results mean_results = pd.DataFrame({     'Category': ['Free apps', 'Premium apps'],     'Mean Rating': [mean_rating_free, mean_rating_premium],     'Mean Bayesian Average': [mean_bayesian_free, mean_bayesian_premium] })  # Combine ratings for boxplot categories = ['Free apps', 'Premium apps'] ratings_data = [df_h2a[df_h2a['category'] == cat]['rating_app'] for cat in categories]  plt.figure(figsize=(5, 3)) plt.boxplot(ratings_data, labels=categories, patch_artist=True) plt.ylabel('Ratings') plt.xlabel('App Category') plt.grid(axis='y', linestyle='--', alpha=0.7)  plt.show()}`

The apps that require upfront payment receive a higher rating on average then free apps, shown in @fig-free-vs-paid. This can indicate that users perceive as being of higher quality. The greater spread of ratings for free apps, may indicate that the app quality varies more. This provides sufficient evidence in support of hypothesis H2a.

Level 0 and 1 have the highest overall downloads, as shown in @fig-downloads-free-access by quite a margin (40 billion downloads (0.4e11)) compared to the other apps. These apps under level 0 and 1 have free access to all features. Hypothesis 2b suggests that the variance in rating between "free access to all feature apps" and "free access to not all features or paid apps" is a sign of quality disparity.

@tbl-free-access shows the variance and standard deviation between "free access to all feature apps" and "free access to not all features or paid apps". From which we can conclude that there is not a big statistical difference. Roughly, 0.02 and 0.01 difference in variance and standard deviation rating respectively.

`{python} #| label: tbl-free-access #| tbl-cap: "Variance (and std) difference. Between free access to all feature apps and free access to not all features or paid apps" #| echo: false #| warning: false #| error: false   df_h1a = df_level_combined.copy()  # if level is 0 or 1 then new column category is 'Free apps' df_h1a['category'] = ['Free all feature apps' if level in ['0', '1'] else 'Free/Paid not all feature apps' for level in df_h1a['level']]  # Calculate variance and standard deviation for each category df_stats_h1a = df_h1a.groupby('category')['rating_app'].agg(['var', 'std']).reset_index()  # Rename columns for clarity df_stats_h1a.rename(columns={'var': 'variance in rating', 'std': 'standard deviation in rating'}, inplace=True)  Markdown(tabulate(df_stats_h1a, headers=df_stats_h1a.columns))}`

@fig-free-access visualizes variance with outliers. It shows that both categories have a similar median rating close to 4.5, with "Free/Paid not all feature apps" being slightly lower. Both categories seem to have a lot of outliers under 3, with 'free all feature apps' having more outliers in 2 and 1.

`{python} #| label: fig-free-access #| fig-cap: "Boxplot of Ratings by App Category" #| echo: false #| warning: false #| error: false  # Step 1: Add 'category' column based on level df_h1a = df_level_combined.copy() df_h1a['category'] = [     'Free all feature apps' if level in ['0', '1'] else 'Free/Paid not all feature apps'      for level in df_h1a['level'] ]  # Step 3: Create a boxplot for ratings categorized by 'category'  # Prepare data for custom boxplot categories = df_h1a['category'].unique() ratings_data = [df_h1a[df_h1a['category'] == category]['rating_app'] for category in categories]  # Custom boxplot plt.figure(figsize=(5, 3)) plt.boxplot(ratings_data, labels=categories, patch_artist=True) plt.ylabel('Ratings') plt.xlabel('App Category') plt.grid(axis='y', linestyle='--', alpha=0.7)  plt.show()}`

The variance and standard deviation is minimal between the two categories, as shown in @tbl-free-access . @fig-free-access illustrates that both categories receive high ratings, with significant number of outliers. These outliers can be interpreted as variability in user satisfaction. The slighty higher median in 'Free all feature apps' may imply that users prefer this over 'Free/Paid not all feature apps'. However, this is marginal and would probably require statistical validation. Thus, the evidence to suggest level 0 and 1 have more variance is inconclusive, leading to rejection of hypothesis H2b.

### Variance in Ratings {#sec-variance-rating}

This section will attempt to answer the following hypothesis regarding the variance in ratings

*H2c: Fully premium apps (level 5) and premium version of level 2 will have less variance in their ratings, while all other levels will have more.*

Firstly, let us consider the overall rating distribution. The average and Bayesian average (adjusting for total reviews) are relatively the same across all revenue levels, as shown in @fig-proportion-rating.

`{python} #| label: fig-proportion-rating #| fig-cap: "Proportion of Ratings Across Levels" #| echo: false #| warning: false #| error: false  ratings_across_level = df_level_combined.copy() # Group by 'level' and calculate mean for 'rating_app' and 'bayesian_average' average_ratings = ratings_across_level.groupby('level')['rating_app'].mean() bayesian_ratings = ratings_across_level.groupby('level')['bayesian_average'].mean() # Plotting the ratings across levels plt.figure(figsize=(5, 3))  # Bar plot for ratings and Bayesian ratings average_ratings.plot(kind='bar', width=0.4, position=1, label='Average Rating', color='blue', alpha=0.6) bayesian_ratings.plot(kind='bar', width=0.4, position=0, label='Bayesian Rating', color='green', alpha=0.6)  # Adding labels and title plt.xlabel('Level') plt.ylabel('Rating') plt.legend() plt.xticks(rotation=0)  # Show plot plt.tight_layout() plt.show()}`

Despite the similarities in average rating, the variance across levels does show some major differences, as illustrated in @fig-variance-rating. However, when adjusted for total reviews using a Bayesian average rating, the differences in variance diminishes. This adjustment smooths out fluctuations, offering a more consistent representation of the ratings.

<!-- Notably, certain levels, particularly paid apps (levels 2 Premium and 5), exhibit strong outliers. (Misschien ben ik gewoon dom, maar ik snap niet hoe dit volgt uit die figuur. Daarom heb ik het weggelaten). -->

`{python} #| label: fig-variance-rating #| fig-cap: "Variance of Different Attributes Grouped by Level" #| echo: false #| warning: false #| error: false  variance_rating = df_level_combined.copy()  # Assuming your dataframe is named df columns_to_calculate = ['rating_app', 'bayesian_average'] variance_specific = variance_rating.groupby('level')[columns_to_calculate].var().reset_index()  # Melting the dataframe to long format for easier plotting variance_melted = variance_specific.melt(id_vars='level', var_name='Attribute', value_name='Variance')  plt.figure(figsize=(12, 6)) sns.barplot(data=variance_melted, x='level', y='Variance', hue='Attribute', palette='viridis') plt.xlabel('Level') plt.ylabel('Variance') plt.xticks(rotation=45) plt.legend(title='Attribute', loc='upper right') plt.tight_layout() plt.show()}`

@fig-var-rating-other-premium illustrates a significant difference in the variance of ratings. Premium apps tend to have a higher variance, with more outliers.

`{python} #| label: fig-var-rating-other-premium #| fig-cap: "Variance in Ratings for Other vs Premium Apps" #| echo: false #| warning: false #| error: false   df_level_combined_h2b = df_level_combined.copy()  # Filter on level 5 and others df_level_combined_h2b['category'] = np.where(df_level_combined_h2b['level'].isin(['2 (Premium)', '5']), 'Premium apps', 'Other apps')  # relevant columns relevant_columns_h2b = ['category', 'rating_app', 'bayesian_average']  # filter the relevant columns df_level_combined_h2b = df_level_combined_h2b[relevant_columns_h2b]  # Filtering data for Free and Premium apps other_apps = df_level_combined_h2b[df_level_combined_h2b['category'] == 'Other apps'] premium_apps = df_level_combined_h2b[df_level_combined_h2b['category'] == 'Premium apps']  # Calculating variances for ratings and bayesian averages other_variance_rating = other_apps['rating_app'].var() premium_variance_rating = premium_apps['rating_app'].var()  # Creating a bar plot for variances in ratings fig, ax = plt.subplots(figsize=(5, 3)) ax.bar(['Other apps', 'Premium apps'], [other_variance_rating, premium_variance_rating], color=['skyblue', 'orange']) ax.set_ylabel('Variance in Ratings', fontsize=12) ax.set_ylim(0, max(other_variance_rating, premium_variance_rating) * 1.2)  plt.tight_layout() plt.show()}`

@fig-var-bayesian-other-premium portrays the variance of the ratings and bayesian variance. For level 5, we see that the variance is one of the lowest when adjusted by Bayesian average. This difference may arise because users who are satisfied with the app tend to rate the app highly, while users who are not satisfied, tend to rate it much lower, having paid for the app.

`{python} #| label: fig-var-bayesian-other-premium #| fig-cap: "Variance of Attributes Across Different Levels" #| echo: false #| warning: false #| error: false  variance_rating = df_level_combined.copy()  # Assuming your dataframe is named df columns_to_calculate = ['rating_app', 'bayesian_average'] variance_specific = variance_rating.groupby('level')[columns_to_calculate].var().reset_index()  # Melting the dataframe to long format for easier plotting variance_melted = variance_specific.melt(id_vars='level', var_name='Attribute', value_name='Variance')  # Melting the dataframe to long format variance_melted = variance_specific.melt(id_vars='level', var_name='Attribute', value_name='Variance')  # Plotting line plot with seaborn plt.figure(figsize=(5, 3)) sns.lineplot(data=variance_melted, x='level', y='Variance', hue='Attribute', marker='o', palette='Set1') plt.xlabel('Level') plt.ylabel('Variance') plt.xticks(rotation=45) plt.legend(title='Attribute') plt.tight_layout() plt.show()}`

In conclusion, the variance across all levels show that level 5 has the highest variance for rating and the lowest variance for bayesian rating, as shown in @fig-var-bayesian-other-premium. The bayesian average seems more reliable regarding the overall app performance. The premium apps may have polarized feedback due to high user expectations. In short, this provides sufficient evidence to support hypothesis H2c.

### Correlation between Sample and Premium Apps {#sec-correlation}

This section serves to test the following hypothesis.

*H2d: For apps that utilize a sample and a premium version of the same app (level 2), the rating of the paid-for version is positively associated with the rating of the free version of the same app.*

Revenue level 2 has two versions of the same app: a sample and a premium version.

@tbl-correlation shows that the correlation between ratings of sample and premium apps is considered moderate positive with 0.35. The correlation between the Bayesian average rating of sample and premium apps is considered moderate to strong positive correlation with 0.5.

`{python} #| label: tbl-correlation #| tbl-cap: "Correlation ranking between sample and premium" #| echo: false #| warning: false #| error: false  df_sample_h3 = df_level_combined[df_level_combined['level'] == '2 (Sample)'] df_premium_h3 = df_level_combined[df_level_combined['level'] == '2 (Premium)'] df_mapping_h3 = df_mapping_level_2.copy()  # relevant columns relevant_columns_h3 = ['my_app_id', 'level', 'rating_app', 'bayesian_average'] relevant_columns_mapping_h3 =  ['Sample app name',    'Premium app name']  # filter the relevant columns df_sample_h3 = df_sample_h3[relevant_columns_h3] df_premium_h3 = df_premium_h3[relevant_columns_h3] df_mapping_h3 = df_mapping_h3[relevant_columns_mapping_h3]  # Merge mapping dataframe with sample dataframe and premium dataframe df_mapped_h3 = (     df_mapping_h3     .merge(df_sample_h3[['my_app_id', 'bayesian_average', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating', 'bayesian_average': 'Sample Bayesian Average'})     .merge(df_premium_h3[['my_app_id', 'bayesian_average', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')     .drop(columns=['my_app_id'])     .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating', 'bayesian_average': 'Premium Bayesian Average'}) )  # Correlation Coefficient correlation_rating_h3 = df_mapped_h3["Sample Rating"].corr(df_mapped_h3["Premium Rating"])  # Correlation Coefficient for Bayesian averages correlation_bayesian_rating_h3 = df_mapped_h3["Sample Bayesian Average"].corr(df_mapped_h3["Premium Bayesian Average"])  correlation_data_h3 = {     "Metric": ["Sample Rating vs Premium Rating", "Sample Bayesian Average vs Premium Bayesian Average"],     "Correlation Coefficient": [correlation_rating_h3, correlation_bayesian_rating_h3] } correlation_data_h3= pd.DataFrame(correlation_data_h3)  Markdown(tabulate(correlation_data_h3, headers=correlation_data_h3.columns))}`

@tbl-correlation shows moderate to strong positive correlation when using the bayesian average rating. This provides sufficient evidence to support hypothesis H2d.

## Conclusion

```{=html}
<!--

| Hypothesis | Support                         | Sufficient evidence? |
|------------|---------------------------------|----------------------|
| H1a        | @sec-quality-free-paid-apps     | Inconclusive         |
| H1b        | @sec-distribution-app-downloads | Yes                  |
| H1c        | @sec-sample-premium-apps        | Yes                  |
| H1d        | @sec-gaming-apps                | Yes                  |
| H2a        | @sec-quality-free-paid-apps     | Yes                  |
| H2b        | @sec-rating                     | No                   |
| H2c        | @sec-correlation                | Yes                  |

Omdat het zo expliciet benoemd wordt in iedere sectie, is deze tabel denk ik niet meer nodig?

-->
```
The six revenue strategies proposed by @djaruma2023 show distinct relationships with app success, as measured by popularity and ratings. Each model offers unique trade-offs between accessibility and user satisfaction.

Level 0 and 1, which provide the app to the user for free, dominate in popularity, achieving the highest number of downloads (approximately 40 billion). However, they show variability in their rating. This suggests that free apps attract large audiences but often struggle with quality consistency. Still, their accessibility makes them widely appealing.

Freemium models, such as level 2, 3 and 4, show more variability in ratings compared to fully premium apps. This may reflect differing user expectations and satisfaction levels. Despite lower average ratings than upfront payment models, freemium apps remain popular, as they allow users to try features before committing financially.

For revenue level 2 (sample and premium versions), a moderate-to-strong positive correlation exists between the ratings of free and premium versions. This suggests that the quality of the free version strongly influences how users perceive the premium version. Positive experiences with the sample version can encourage upgrades.

Apps requiring upfront payment (level 5) achieve the highest average ratings and exhibit the lowest variance, especially when Bayesian averages are considered. These apps are perceived as higher quality, likely due to clear value propositions and no in-app purchases. However, their popularity is more limited compared to free or freemium models. Users tend to expect premium apps to deliver a polished experience, and ratings reflect this perception.

All in all, the revenue model chosen significantly affects an app’s success. Free models (levels 0 and 1) maximize reach, driven by their accessibility, but suffer from variable quality. Freemium models (levels 2, 3, and 4) offer a balance, achieving moderate success in both popularity and ratings. Fully premium apps (level 5) excel in user satisfaction, with consistently high ratings, but they trade off reach for exclusivity.

In conclusion, no single model is the best overall. Free models are best for capturing large audiences, freemium models appeal to users who want flexibility, and premium models shine in delivering consistent quality.

## Ethical Considerations

<!--  -   No individual data is used, and research was based on publically available Google Play Store data. -   App data may include sensitive business information (e.g., competitive analysis implications). Sharing raw data or revealing proprietary metrics could inadvertently harm developers or companies. -   The findings could influence app developers, marketers, or policymakers. For example, conclusions about the profitability of certain monetization methods (e.g., ads, in-app purchases) might encourage exploitative practices.  -->

This research relies on data that is mostly publically available in the Google Play Store. Within this data, no individual user data is involved at any stage, making sure we circumvent any possible privacy concerns [@tikkinen-piri2018]. However, there are still risks tied to the use of app data. Even publicly available information can reveal sensitive business insights. For example, metrics tied to competitive analysis might unintentionally expose proprietary strategies. Therefore, although the data is public, the patterns that emerge may still harm developers by giving competitors an advantage. Therefore, we make sure to not single out specific apps.

The potential implications of this research could directly influence app developers, marketers, and policymakers. For instance, insights into the profitability of specific monetization methods—such as ads or in-app purchases—might guide businesses in optimizing their revenue strategies. This connection between research and practical applications can be valuable. However, it also raises ethical concerns. If certain methods are shown to be highly effective, developers might adopt exploitative practices, prioritizing profits over user experience [@mileros2024]. This highlights our dual responsibility: we must provide actionable insights while ensuring they are not misused. We aim to inform through this research, but we also emphasize the need for careful and ethical application of our conclusions.

# Discussion <!--500-700 words -->

<!-- Insightful discussion of findings in relation to the research question and literature. Reflection on practical implications and contributions to the ongoing debate.  Content: Provide a thoughtful discussion of the findings in relation to the research question and the literature. Reflect on the practical implications and contributions to the academic debate.  Key Elements: Reflection on findings. Linkage to existing literature. Practical -->

## Reflection on the Findings

<!-- Later checken of dit nog goed aansluit op results -->

The analysis reveals clear trade-offs between the six revenue models and app success. Free models dominate in popularity due to accessibility but struggle with consistent quality. Freemium models strike a balance, appealing to users seeking flexibility, while premium apps deliver the highest quality but have limited reach. These findings suggest that app developers must align their revenue strategies with their target audience’s expectations and priorities, balancing reach, user satisfaction, and profitability.

H1a: Wel meer downloads, niet meer variance

H1b: KLOPT / SUPPORTED (maar: Tiktok)

H1c: KLOPT / SUPPORTED: Sample heeft veel meer downloads (premium maar 1%)

H1d: KLOPT / SUPPORTED: Games met level 3/4 krijgen meer downloads

H2a: KLOPT / SUPPORTED

H2b: NOT SUPPORTED: Premium apps hebben juist meer variance, bij Baysian wel. Dus onduidelijk -\> misschien meer onderzoek nodig.

H2c: KLOPT / SUPPORTED, maar de sterkte van correlation hangt af van normaal average vs Baysian average.

## Limitations

Downloads do not necessarily indicate revenue for freemium models [@djaruma2023]. The time the user spends on an app and the purchases made within this app [@ross2018] are better measures of the revenue for freemium applications.

The data used for this project was collected before the launch of Tiktok, the social media platform with over 900 million users worldwide [@Ceci2024TikTokUsers]. As is mentioned in Section @revenue-estimation, Tiktok has a business model that relies more on user retention

We have found certain factors () are correlated with higher downloads, and x, y, z are correlated with higher ratings. However, it is important to note this does not necessarily imply a causal relationship. Other confounding variables may be at play. Therefore, we cannot assume implementing these revenue strategies will definitely boost downloads and/or ratings.

## Practical Implications for Businesses

As the results only show correlations and no causal relationships, it is important to not over-inflate the significance of these results. However, it may still be interesting to consider what revenue strategy best fits your specific app.

Best revenue models.

## Future Research Directions

On other datasets

Further investigate hypotheses that were disproven.

# References

::: {#refs}
:::
