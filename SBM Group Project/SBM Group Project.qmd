---
title: "**The Economics of App Success: How Revenue Streams Influence Downloads and User Ratings**"
subtitle: "Group Assignment - Strategy and Business Models"
author: "Group 5"
date: "November 28, 2024"
date-format: DD/MM/YYYY # Set date format to long
crossref:
  fig-prefix: Figure   # (default is "Figure")
  tbl-prefix: Table    # (default is "Table")
format: 
  pdf: #Output pdf
    documentclass: article
    fig-pos: "H"
    number-sections: true
    toc: true #table of contents
    toc-title: Contents #name table of contents
    papersize: a4
    fontsize: 12pt
    fontfamily: mathptmx
    geometry:
      - top=25mm #top margin
      - left=25mm #left margin
    pdf-engine: pdflatex
    cap-location: bottom # Set table caption location to bottom
    include-in-header: 
      - text: |
          \usepackage{graphicx}
    include-before-body:
      - text: |
          \vspace{2em}
          \begin{center}
            \includegraphics[width=0.3\textwidth]{figures/jads.png}
          \end{center}
          \vspace{3em}
          \newpage
bibliography: references.bib
bibliographystyle: apa
execute: 
  enabled: true
jupyter: python3
---

<!-- horizontal line -->

\newpage

# Introduction <!-- 800-1,000 words -->

<!-- Content: Introduce the topic and explain its relevance in both academic and practical contexts. Justify the research gap and formulate a clear and insightful research question.  Key Elements: Background of the topic. Identification of the research gap. Relevance to current business practices. Research question. -->

With the every-growing popularity of cellphones [@charted2023], the popularity of mobile applications is also steadily increasing. In 2024, mobile applications are estimated to generate over \$900 billion in revenue [@global2019]. Generally, mobile applications ('*apps*' from here on) tend to be categorized in three different categories [@roma2016]. Paid apps are the most transparent; they revenue is based on an up-front purchase by the user. Free apps, on the other hand, require no purchase by the user at any stage. According to @roma2016, these apps make their revenue from deals with third-parties, either through advertisement or other purposes such as market information.

Finally, freemium apps are, as the name suggests, a middle-ground between free and premium. Users get access to a basic version of the application first and can unlock more features through an in-app payment [@kumar2014]. Of these three revenue models, freemium is the most commonly used and the most [@salehudin2021] and leads to more downloads as well as revenue [@liu2014].

## Academic Background

<!-- Kort samengevat: Wat is de wetenschappelijke consensus over dit topic? Dit wordt verder uitgediept in de Theory and Hypothesis sectie.-->

Most research uses these three established categories—paid, freemium, and free—when discussing revenue models for apps. However, by limiting the discussion to these three terms, nuances within these categories might be missed.

In a review paper from 2023 [@djaruma2023], different levels of monetization are suggested based on previous literature. These levels provide a clear framework for the revenue models of mobile apps, and are briefly summarized in @tbl-levels.

| Strategy | Description |
|--------------------------|----------------------------------------------|
| Level 5: Premium | Pay to use the application. This either happens up-front, or after a trial period. |
| Level 4: Semi-premium | Use a limited number of features for free. Unlock the app with all features through an in-app purchase. |
| Level 3: In-app advertisement and in-app purchases | Free application with ads, encouraging users to remove ads or to make in-app purchases. |
| Level 2: Sample and premium | Two different versions of the same app. One is a version with limit features and/or ads. The other version is a premium version. |
| Level 1: In-app advertisement | Only one version of the app, with only ads and no in-app purchases. |
| Level 0: Free | The app has no monetization. However, money can still be made through selling user information. |

: Six levels of monetization for apps {#tbl-levels}

The monetization levels as shown in @tbl-levels are not meant to illustrate the revenue a firm will earn. It is meant to show how much customers may engage in paying for features or services at different levels.

Level 0 is an app that is completely free to use. This requires no payment nor ads, but may still make revenue through selling user data. This risks both ethical pitfalls, as well as scrutiny from customers [@djaruma2023].

Level 1 is an app that requires no user payment, and only makes revenue through ads. These may also make revenue by selling user information. Large social media apps such as Facebook and Instagram fall in this category [@djaruma2023].

Level 2 allows the user to purchase either a free or premium version. The free app has limit features; if the user wants to experience the app in full, they will have to purchase the premium version. However, this does run the risk of 'cannibalization', wherein users never upgrade to the premium version. Therefore, it is of the utmost importance to find the right amount of features to include in the free version [@djaruma2023].

Level 3 combines advertisement and purchases. Many pay-to-win games use this strategy [@nieborg2016]: users can sit through ads and wait a long time for certain rewards, or they can pay for immediate rewards.

Level 4 is similar to level 2: a user has a free trial version, and can upgrade to a premium version. This is often seen in subscription-style apps [@chen2023].

Level 5 is a totally premium app, where a user has to pay up-front to access as features. This level requires a high-quality app, as users will not pay for an app that is not polished.

<!-- Ik heb dit expres kort gehouden, aangezien we ook nog een uitgebreidere literatuur review hebben. Maar, misschien moet dit toch nog iets langer? -Noa -->

## Societal Background

<!-- Is there any tie to practical contexts? How is this relevant to current business practices? -->

Currently, most apps utilize the freemium revenue model [@salehudin2021]. However, as discussed in @djaruma2023, there are many revenue models between completely premium and completely free. A more fine-grained classification of app revenue models beyond the traditional "paid-freemium-free" framework holds significant societal and business implications.

For society, such distinctions enhance transparency. Some monetization models, such as free or ad-filled apps, may rely on selling user information as a source of revenue [@bamberger2020]. Therefore, clearer distinctions regarding the revenue model will empower consumers to make informed choices. It may also enable policymakers to identify and regulate exploitative practices, such as manipulative microtransactions or intrusive ad models, ensuring all applications align with ethical and legal standards [@mileros2024].

For businesses, this paper should unlock more insight into the effectiveness of different revenue streams. This will allow developers to tailor monetization strategies to specific audiences. Furthermore, both consumers and regulatory bodies are growing more concerned with the privacy concerns of apps, especially ones that rely on market information [@mileros2024]. A granular understanding helps businesses adapt, aligning profitability with sustainability and ethical considerations.

<!-- Ik ben niet helemaal blij met de flow van dit stuk, ik mis een mooie conclusie. Maar, ik kan niet bedenken :(. Dit moet later toegevoegd worden -Noa. -->

## Research Gap

<!-- Kort samengevat: Wat is de relevantie? -->

In short, apps play an increasingly important role in our techno-centric society. To improve the user experience and increase profits, consideration of revenue models is key. Despite the great depth of research on this topic, literature tends to be focussed on the three big categories of paid, freemium, and free. This lack of nuance prevents us from understanding the fine-grained details that may help improve future apps.

<!-- Wat is de research gap? En wat is dus de onderzoekvraag? -->

The levels of monetization proposed by @djaruma2023 offer an opportunity to capture this nuance. However, no empirical study has yet applied their framework, as their paper was published only last year. By using this framework to examine how different revenue streams impact app popularity, this study aims to provide valuable insights into consumer preferences. Therefore, this paper seeks to answer the question: *How are the six different revenue models proposed by @djaruma2023 correlated with app success?*

<!-- Wederom: kort maar krachtig, of té kort? -Noa -->

# Theory and Hypotheses <!-- 1,000-1,200 words -->

In this section, prior research into the topic of revenue streams and its correlation to success in apps will be discussed. As mentioned in the Introduction section, this paper will apply the six levels of revenue as proposed by @djaruma2023 to app data. The following section will contain a holistic overview of the existing research, as well as hypotheses that arise from this theoretical framework.

## Literature Review {#sec-literature-review}

According to @djaruma2023, there are six distinct revenue strategies for apps. However, it is important to point out they were not the inventors of these revenue strategies; these arose from the literature they analyzed. In the following section, we shall look at the previous research into these revenue strategies.

Firstly, biggest portion of apps are free to download. In fact, this contributes over 95% of all apps in both the Google Play Store as well as the IOS App Store [@statista2023apps]. But, this does not mean the apps do not generate revenue; they might implement advertisements, in-app purchases or sample and premium versions to still make a profit.

@sensortower2023forecast has predicted global spending on in-app advertisements will reach over 233 billion U.S. dollars in 2026. These funds are an important source of income for mobile app developers [@gao2022; @maddodi2023].

Aside from advertisements, there are two different revenue strategies to consider: in-app purchases, and a trial and premium version of the same app. Both of these are considered "freemium" in recent literature. @kumar2014 describes freemium as apps for which users get basic features for free and can update it using a payment. This can be done both through in-app payments, as well as purchasing the premium version of an app.

Another revenue strategy used in apps are in-app payments. This strategy is often used in games. More specifically, games that fall in the "pay-to-win" category [@nieborg2016]. These games often require the user to wait or watch advertisements, which they can circumvent by paying. Some games also allow users to buy special features, such as the look of their avatar or special powers. Nonetheless, while in-app purchases are a proven revenue strategy, it does come with risks. Notably, in-app payments are also prone to security risks, as it requires more complex interactions and involves more participants than traditional payment [@yang2019]. Therefore, developers need to make sure their payment methods are secure before launching an app with this revenue strategy.

In-app purchases are not the only solution for offering freemium services. A different method is offering two different versions: a free one, and a paid one. The free version often has limit features combined with ads, meaning you make a profit by advertisements [@appel2020]. This is combined with the revenue of the premium version.

To answer the question *"How are the six different revenue models as proposed by @djaruma2023 correlate to the success of an app?"*, we must first define what constitutes to success. In this paper, success will be defined by a couple of factors: popularity, rating, and estimated revenue.

### Popularity

The popularity of an app can be measured by the number of downloads. It is important to note the popularity of an app is complex, and is not solely dependent on the chosen revenue model. Other features, such as whether an app is featured on charts, whether it has frequent updates, and word-of-mouth awareness, will also impact the popularity of an app [@aydingokgoz2021]. However, despite these other variables, to versions of the same app will still have drastically different performances with different revenue streams [@liu2014].

Building on this, we hypothesize that revenue models associated with fewer barriers to entry will drive higher downloads overall, but the impact of these models may vary by app type and market context.

*H1a: Apps that allow the user to have free access to all features (level 0 and 1) will have the highest amount of downloads overall.*

As @djaruma2023 has shown, the most highly ranked apps are level 1. These apps are the big social media platforms such as Instagram and Facebook. Therefore, we expect this to be reflected within our data and the following to be true.

*H1b: The apps with the most downloads will be level 1.*

Freemium apps can be implemented with either in-app purchases or different versions. For the latter, we expect more downloads to be generated by the free app, than its premium counterpart. As demonstrated by @liu2012freemium, users tend to download the trial version before comitting to a premium version. Thus, the following is likely to be true.

*H1c: For apps that utilize a sample and a premium version of the same app (level 2), the free versions of an app will have more downloads than their paid-for counterpart.*

### Rating

The downloads of an app are not everything. An app can be downloaded often, but may not be highly rated. Ratings provide valuable insights into user satisfaction, which often reflects the perceived quality and value of an app. Therefore, we hypothesize revenue models that prioritize short-term gains may achieve high download counts but could negatively affect ratings if users feel misled or dissatisfied.

The main draw of a freemium model is to attract users, and have them update to a paid version [@kumar2014]. However, as @kumar2014 points out, this can be a double-edged sword. Too few features, and it may not be attractive to users. Too many features, and the users will not update. This leads to the following hypothesis.

*H2a: Apps that require the user to pay to unlock features (level 2, 3, and 4) will tend to have lower ratings than the version that requires payment upfront (level 5).*

The majority of the apps are free-to-use [@djaruma2023]. However, this means there might be more difference in quality between these apps, as the barrier to downloading is lower for free apps than paid or freemium apps [@mileros2024]. Therefore, we postulate the following.

*H2b: Apps that allow the user to have free access to all features (level 0 and 1) will have more variance in their rating, as quality can vary for free-to-access apps.*

In the same vein as H2a, users have more realistic expectations of paid apps compared to apps that require you to unlock features [@kumar2014]. Therefore, more users downloading premium apps will be satisfied with their purchase, leading to less variance. Thus, the following should follow from our data.

### Revenue Estimation {#revenue-estimation}

<!-- Dit stuk kan later ook nog verschoven worden naar de discussie als dat beter is voor de flow. -Noa -->

It is important to point out downloads and ratings likely do not directly correlate to the actual revenue of an app. The revenue of apps "premium" apps that require an upfront payment, the revenue is relatively simple to track and compare. However, for apps that rely on advertisement, in-app purchases and/or selling market information, this is harder to track.

For apps that solely on advertisement, time retention can be a good measure of revenue [@ross2018]. However, this only works if the app solely relies on ads. An example of this given by @djaruma2023 is TikTok: this app relies not only on advertisement, but also on users purchasing products through its shop. Therefore, using solely the time retention would not accurately capture the revenue of an app with both revenue streams. Furthermore, the selling of user data is usually not publicized, meaning it is not possible to know the revenue from this.

Unfortunately, our data only contains the price of "premium" app versions. The data does not include any details regarding in-app purchases nor time-retention. Because of this lack of sufficient data, solely downloads and ratings will be taken into account as indicators of success.

<!-- Officieel mag je dus maar 3 hypothesen, maar ik heb ze onderverdeeld. Zou dit mogen? -Noa -->

# Methods and Data <!-- 1,000-1,200 words -->

```{=html}
<!--

Detailed description of the dataset, clear explanation of variable translation.
Proper use of statistical methods, with careful consideration of assumptions and appropriate handling of violations.

Content: Describe the dataset(s) used, explain variable selection and translation, and provide a detailed explanation of the statistical methods applied. Justify the methodological approach and handle assumptions rigorously.
Key Elements:
Dataset description.
Explanation of variable selection.
Statistical methods and justification.
Handling of assumptions.
-->
```

In this section, we will discuss the dataset and methods used to test the hypotheses outlined in the previous section. The focus lies on providing a comprehensive description of the dataset, including its structure and the variables it contains, followed by an explanation of the variable selection process. Additionally, we outline the statistical methods applied and discuss how assumptions, such as missing values and potential biases, were addressed to ensure the robustness of our analysis.

## Dataset Description

<!--Omschrijf de data: hoeveel instances, welke variables, waar gaat de data over?-->

The dataset used in this research comprises 1,016,666 instances and 27 variables, offering a comprehensive overview of mobile applications across various revenue models. Each instance corresponds to a single app, capturing details about its characteristics, user engagement, and monetization strategies. Key variables include the app's unique identifier (my_app_id), the number of downloads (num_downloads), the average rating (rating_app), and the number of ratings received (nb_rating). These variables provide critical insights into app performance metrics.

Additional variables include pricing details (price_gplay), information about in-app purchases (in_app), and whether the app contains advertisements (has_ads). Other attributes, such as content ratings (content_rating_app) and metadata about the app developer (developer_name), further enhance the dataset’s richness by adding contextual information.

Several variables, such as whats_new (completely null) and in_app_product (89.57% null), were excluded from the analysis due to their high proportions of missing data. Conversely, variables with minor missingness (e.g., date_published, privacy_policy) were retained after appropriate preprocessing. This curated dataset is the foundation for examining monetization strategies and their relationship to app performance metrics like downloads and user ratings.

## Variable Selection

```{=html}
<!-- Welke variabelen gebruiken wij? Welke hebben we eruit gehaald? (Hierover uitbreiden in Handeling of Assumptions).

Hoe definiëren we de 5 levels?-->
```

The analysis focuses on a subset of 13 variables selected from the dataset, as shown in Table 2 below. These variables were chosen for their relevance to our research questions, capturing information about app characteristics, user engagement, and monetization strategies.

<!-- Table 2: Selected Variables for Analysis -->

| **Variable Name** | **Description** |
|--------------------------|----------------------------------------------|
| `my_app_id` | Unique identifier for each app. |
| `num_downloads` | Number of downloads for the app. Key indicator of app success. |
| `rating_app` | Average user rating. Measures user satisfaction. |
| `nb_rating` | Number of ratings received. Reflects user engagement. |
| `price_gplay` | Price of the app. Used to differentiate free vs premium apps. |
| `in_app` | Boolean indicating whether the app has in-app purchases. |
| `has_ads` | Boolean indicating whether the app includes advertisements. |
| `content_rating_app` | Content rating of the app (e.g., Everyone, Teen). |
| `categ_app` | App category (e.g., Productivity, Games). Groups apps by functionality. |
| `developer_name` | Name of the app developer. Provides context on developer reputation. |
| `developer_info` | Additional metadata about the developer (e.g., location, website). |

To systematically explore monetization strategies, we classified the apps into six distinct levels based on their monetization models. These levels reflect varying approaches to generating revenue, ranging from completely free apps to fully premium paid apps.

-   **Level 0**: Apps with no monetization, offering free services without ads or in-app purchases.
-   **Level 1**: Free apps monetized solely through ads.
-   **Level 2**: Freemium model, employing both free sample apps with limited functionality (and potentially ads) and paid premium apps with full features.
-   **Level 3**: Apps combining ads and in-app purchases, monetizing through both strategies.
-   **Level 4**: Freemium apps monetized entirely through in-app purchases, removing ads for a seamless user experience.
-   **Level 5**: Fully premium paid apps, with no ads or in-app purchases, delivering a premium experience.

This classification is grounded in theoretical frameworks, such as the monetization levels proposed by @djaruma2023, and allows for a nuanced analysis of how different revenue models impact app success metrics like user ratings and downloads. Our systematic categorization facilitates a deeper understanding of the relationship between monetization strategies and app performance.

## Statistical Methods

To test our hypotheses, we employed a combination of descriptive statistics, text processing, and machine learning techniques, ensuring a rigorous approach to analyzing the dataset. Descriptive statistics were used to explore distributions and trends in key metrics such as num_downloads, rating_app, and price_gplay. Applications were categorized into six monetization levels using binary indicators (is_free, in_app, and has_ads), while preprocessing of price data facilitated the distinction between free and paid applications. These steps established a structured foundation for investigating relationships between monetization strategies and app performance.

For the paired application analysis within Level 2, we applied Term Frequency-Inverse Document Frequency (TF-IDF) vectorization combined with cosine similarity to app names, allowing us to measure textual similarity [@Widianto2023]. Logical pairings were refined through prefix matching and the identification of indicative terms like "Free" or "Pro." This process was further validated by ensuring paired apps shared the same developer, using metadata from developer_name and developer_info. While effective, this approach acknowledged potential limitations, such as ambiguity in naming conventions, which were flagged as edge cases for transparency.

To address potential biases in app ratings caused by low review counts, we calculated a Bayesian average, adjusting raw ratings by combining the global average with individual app ratings weighted by review volume [@MOYEED2005807]. This provided a more balanced measure of user satisfaction, reducing the influence of apps with disproportionately few reviews. Scatter plots and box plots were employed to visualize the relationships between monetization levels and user engagement metrics, offering valuable preliminary insights into patterns within the data. These visualizations, alongside the Bayesian adjustments, laid the groundwork for robust and interpretable results, which are elaborated in the results section.

### Handeling of Assumptions

We addressed missing values by removing rows with critical nulls, such as those in num_downloads, to maintain data integrity. Text-based variables like content_rating_app were standardized to ensure consistency. For price_gplay, currency symbols were removed to facilitate the classification of applications into free or paid categories.

Outliers in metrics like num_downloads were retained if they represented industry-leading applications, as their exclusion could skew the analysis. The use of Bayesian averages mitigated bias in rating_app due to low review counts, providing a more accurate reflection of user satisfaction. Covariance checks were conducted to ensure the absence of multicollinearity among numerical variables, thereby enhancing the reliability of correlation and regression analyses.

Some applications exhibited rare combinations of is_free, in_app, and has_ads that did not fit within the predefined monetization levels. These applications were excluded from the analysis but documented as a limitation. Edge cases in level 2 application pairing were flagged for potential mismatches due to naming ambiguities, ensuring transparency in the classification process.

These methodologies facilitated a systematic and accurate exploration of monetization models and their impact on application performance.

# Results <!-- 800-1,000 words -->

This section analyzes the data using tables and visualizations to test the hypotheses and answer the research question: "*How do the six revenue models proposed by @djaruma2023 correlate with app success?*" These models, described in @tbl-levels, form the basis of the analysis.

The Google Play Store data was categorized into these models, revealing that over 75% of apps fall into levels 0 and 1, while level 2 has the fewest apps (@fig-distribution-amount-apps-levels).

```{python}
#| echo: false
#| warning: false
#| error: false
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from IPython.display import Markdown
from tabulate import tabulate

df_level_combined = pd.read_csv('./data/google_data_levels_combined.csv', dtype={16: 'string'})
df_mapping_level_2 = pd.read_csv('./data/mapping_level_2.csv', dtype={16: 'string'})
```

```{python}
#| echo: false
#| warning: false
#| error: false
#| label: fig-distribution-amount-apps-levels
#| fig-cap: "Distribution of the amount of apps across the revenue levels"

# Assuming df_level_combined['level'] exists
level_counts = df_level_combined['level'].value_counts()
level_counts = level_counts.reindex(["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"])  # Specify the order

# Creating labels for the legend with counts and percentages
total = level_counts.sum()
labels = [f"{level} - {count} ({count / total:.1%})" for level, count in level_counts.items()]

# Plotting the pie chart
plt.figure(figsize=(3, 3))
wedges, texts = plt.pie(
    level_counts, 
    labels=None,  # Hide labels on the pie chart itself
    startangle=90, 
    colors=plt.cm.Paired.colors
)

# Adding the custom legend
plt.legend(wedges, labels, title="Levels", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

plt.show()
```

App success is assessed using metrics like downloads (popularity) and user ratings, while revenue estimation is excluded due to insufficient data (@sec-literature-review). Downloads address hypotheses H1a–H1d, and ratings evaluate H2a and H2b.

## Downloads {#sec-number-of-downloads}

This section addresses hypotheses H1a–H1d in three subsections. In @sec-distribution-app-downloads, download distribution is analyzed to address H1a and H1b. @sec-sample-premium-apps explores download differences between sample and premium level 2 apps for H1c. Finally, @sec-gaming-apps examines gaming app downloads to answer H1d.

### Distribution of app downloads {#sec-distribution-app-downloads}

This section addresses:

H1a: Free-to-access apps (levels 0 and 1) will have the highest total downloads.

H1b: Level 1 apps will have the most downloads.

Download data (@fig-total-average-downloads-by-level) shows significant variation for levels 0 and 1, which account for 75% of apps (@fig-distribution-amount-apps-levels). However, levels 0 and 1 do not dominate in average downloads.

```{python}
#| label: fig-total-average-downloads-by-level
#| fig-cap: "Comparison of Total and Average Downloads by Level"
#| fig-subcap:
#|   - "Total Number of Downloads by Level"
#|   - "Average Number of Downloads by Level" 
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

df_h1b = df_level_combined.copy()

# Calculate the sum of downloads for each level
total_downloads_h1b = df_h1b.groupby('level')['num_downloads'].sum().reset_index()

# Define the order of the levels
level_order = ["0", "1", "2 (Sample)", "2 (Premium)", "3", "4", "5"]

# First bar chart: Total Number of Downloads
sns.barplot(
    data=total_downloads_h1b,
    x='level',
    y='num_downloads',
    hue='level',
    palette='viridis',
    dodge=False,
    order=level_order
)
plt.xlabel('Level')
plt.ylabel('Total Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.tight_layout()  # Adjust layout to avoid overlap
plt.show()

# Second bar chart: Average Number of Downloads
sns.barplot(
    data=df_h1b,
    x='level',
    y='num_downloads',
    hue='level',
    palette='viridis',
    dodge=False,
    order=level_order
)
plt.xlabel('Level')
plt.ylabel('Average Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.tight_layout()  # Adjust layout to avoid overlap
plt.show()

```

As the majority of apps fall under level 0 and 1, these do have the highest overall downloads, as shown in @fig-total-average-downloads-by-level-1. @tbl-downloads-free-access shows just how big the difference between the total downloads is. The apps that are completely free to use (level 0 and 1) have over 40 billion more downloads than the apps that are paid to some extend (levels 2 through 5).

```{python}
#| label: tbl-downloads-free-access
#| tbl-cap: "Difference Total Number of Downloads"
#| echo: false
#| warning: false
#| error: false

# Create a copy of the dataframe
df_h1a = df_level_combined.copy()

# Add the 'category' column based on conditions
df_h1a['category'] = [
    'Free all access' if level in ['0', '1'] else 'Freemium and Premium'
    for level in df_h1a['level']
]

# Calculate the sum of downloads for each category
total_downloads_h1a = df_h1a.groupby('category')['num_downloads'].sum().reset_index()

Markdown(tabulate(total_downloads_h1a, headers=total_downloads_h1a.columns))
```

@fig-distribution-app-downloads reveals significant inequality in download distribution, with a small proportion of apps accounting for the majority of downloads. @fig-distribution-app-downloads-1 and @fig-distribution-app-downloads-2 show similar patterns, suggesting this dominance may not be exclusive to levels 0 and 1, as other levels could exhibit similar trends.

```{python}
#| label: fig-distribution-app-downloads
#| fig-cap: "Distribution of App Downloads (Top-Heavy Analysis)"
#| fig-subcap:
#|   - "All levels except 1"
#|   - "Level 1 Only" 
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

df_h1b = df_level_combined.copy()

# convert float to int for num_downloads
df_h1b['num_downloads'] = df_h1b['num_downloads'].astype(int)

# relevant columns
relevant_columns_h1b = ['my_app_id', 'num_downloads', 'categ_app', 'level', 'developer_name']

# filter the relevant columns
df_h1b = df_h1b[relevant_columns_h1b]

# Filter the dataframe to exclude level '1'
df_no_level_1 = df_h1b[df_h1b['level'] != '1'].copy()

# Sort the dataframe by 'num_downloads' in descending order
df_no_level_1_sorted = df_no_level_1.sort_values(by='num_downloads', ascending=False)

# Calculate the cumulative percentage of downloads
df_no_level_1_sorted['cumulative_percentage_downloads'] = (
    df_no_level_1_sorted['num_downloads'].cumsum() / df_no_level_1_sorted['num_downloads'].sum() * 100
)

# Create a Lorenz curve-style plot for all levels except '1'
plt.plot(
    range(1, len(df_no_level_1_sorted) + 1),
    df_no_level_1_sorted['cumulative_percentage_downloads'],
    label='Cumulative Downloads (All Levels Except 1)'
)
plt.plot(
    [1, len(df_no_level_1_sorted)],
    [0, 100],
    linestyle='--',
    color='gray',
    label='Equality Line'
)

# Add labels and legend
plt.xlabel('Apps (sorted by downloads)')
plt.ylabel('Cumulative Percentage of Downloads')
plt.legend()
plt.grid(True)
plt.show()


# Filter the dataframe for level '1'
df_level_1 = df_h1b[df_h1b['level'] == '1'].copy()

# Sort the dataframe by 'num_downloads' in descending order
df_level_1_sorted = df_level_1.sort_values(by='num_downloads', ascending=False)

# Calculate the cumulative percentage of downloads
df_level_1_sorted['cumulative_percentage_downloads'] = df_level_1_sorted['num_downloads'].cumsum() / df_level_1_sorted['num_downloads'].sum() * 100

# Create a Lorenz curve-style plot for level '1'
plt.plot(
    range(1, len(df_level_1_sorted) + 1),
    df_level_1_sorted['cumulative_percentage_downloads'],
    label='Cumulative Downloads (Level 1)'
)
plt.plot(
    [1, len(df_level_1_sorted)],
    [0, 100],
    linestyle='--',
    color='gray',
    label='Equality Line'
)

# Add labels and legend
plt.xlabel('Apps (sorted by downloads)')
plt.ylabel('Cumulative Percentage of Downloads')
plt.legend()
plt.grid(True)
plt.show()
```

The download range of apps in @tbl-num-downloads-by-level illustrates that level 1 dominates in terms of apps with over 1 billion downloads. Furthermore, level 0 also has a few apps with over 1 billion downloads. Level 0 has the most app downloads between 500 million and 1 billion with 18.

```{python}
#| label: tbl-num-downloads-by-level
#| tbl-cap: "Number of Downloads by Level"
#| echo: false
#| warning: false
#| error: false

downloads_across_level = df_level_combined.copy()

# Define the new bins and labels
bins = [0, 1000000, 100000000, 500000000, 1000000000, np.inf]
labels = ['0-1M', '1M-100M', '100M-500M', '500M-1B', '1B+']

# Recreate the downloads_bin column with the new bins and labels
downloads_across_level['downloads_bin'] = pd.cut(downloads_across_level['num_downloads'], bins=bins, labels=labels)

# Regroup the data by level and the new downloads_bin
grouped_updated = downloads_across_level.groupby(['level', 'downloads_bin']).size().unstack(fill_value=0)


Markdown(tabulate(grouped_updated, headers=grouped_updated.columns))
```

Taking a closer look at the apps provided by @djaruma2023 in @tbl-top-8-apps-paper. We do see that Facebook, Instagram, Spotify, Snapchat and Amazon Shopping fall under level 1.

```{python}
#| label: tbl-top-8-apps-paper
#| tbl-cap: "Top 8 Apps by Downloads (in Billions)"
#| echo: false
#| warning: false
#| error: false


df_h1b = df_h1b[df_h1b['my_app_id'].isin(['com.amazon.mShop.android.shopping', 'com.instagram.android', 'com.facebook.lite', 'com.netflix.mediaclient', 'com.snapchat.android', 'com.spotify.music', 'com.whatsapp', 'com.facebook.orca'])]

df_h1b = df_h1b[['my_app_id', 'num_downloads', 'categ_app', 'level']]

df_h1b['num_downloads'] = df_h1b['num_downloads'] / 1_000_000_000

app_mapping = {
    'com.amazon.mShop.android.shopping': 'Amazon Shopping',
    'com.instagram.android': 'Instagram',
    'com.facebook.lite': 'Facebook Lite',
    'com.netflix.mediaclient': 'Netflix',
    'com.snapchat.android': 'Snapchat',
    'com.spotify.music': 'Spotify',
    'com.whatsapp': 'WhatsApp',
    'com.facebook.orca': 'Facebook Messenger'
}

# Map app names to the 'my_app_id' column
df_h1b['app_name'] = df_h1b['my_app_id'].map(app_mapping)

# Reorder columns for better readability
df_h1b = df_h1b[['app_name', 'num_downloads', 'categ_app', 'level']]


# Rename columns as per requirement
df_h1b = df_h1b.rename(columns={
    'app_name': 'App Name',
    'num_downloads': 'Downloads (in B)',
    'level': 'Level',
    'categ_app': 'Category'
})

df_h1b.sort_values(by='Downloads (in B)', ascending=False, inplace=True)
df_h1b.reset_index(drop=True, inplace=True)
Markdown(tabulate(df_h1b, headers=df_h1b.columns))
```

Free apps are downloaded more often than paid ones (@tbl-downloads-free-access) but not on average (@fig-total-average-downloads-by-level-2). While levels 0 and 1 dominate in total downloads (34.2% and 47.1%, @fig-distribution-amount-apps-levels), their average downloads are not the highest, making evidence for H1a inconclusive.

Level 1 apps, including many social networks (@tbl-top-8-apps-paper), are the most downloaded (@fig-total-average-downloads-by-level-1), though downloads are concentrated among a few (@fig-distribution-app-downloads), supporting H1b.

### Sample and Premium Apps {#sec-sample-premium-apps}

This section tests H1c: Free versions of level 2 apps will have more downloads than their paid counterparts.

Levels 2 (premium) and 5 have the lowest total and average downloads (@fig-total-average-downloads-by-level). A significant disparity exists between level 2 sample and premium app downloads (@fig-total-average-downloads-by-level-2). Only 1.1% of level 2 downloads are attributed to premium apps (@fig-proportion-sample-premium), highlighting the vast discrepancy.

```{python}
#| label: fig-proportion-sample-premium
#| fig-cap: "Proportion of Total Downloads: Sample vs Premium"
#| echo: false
#| warning: false
#| error: false

df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)']
df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)']
df_mapping_h1c = df_mapping_level_2.copy()

# relevant columns
relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app']
relevant_columns_mapping_h1c =  ['Sample app name',	'Premium app name']

# filter the relevant columns
df_sample_h1c = df_sample_h1c[relevant_columns_h1c]
df_premium_h1c = df_premium_h1c[relevant_columns_h1c]
df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]

# Merge mapping dataframe with sample dataframe and premium dataframe
df_mapped_h1c = (
    df_mapping_h1c
    .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})
    .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'})
)

# Calculate metrics
df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads']
df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']

# Calculating total sample and premium downloads
total_sample_downloads = df_mapped_h1c['Sample Downloads'].sum()
total_premium_downloads = df_mapped_h1c['Premium Downloads'].sum()

# Creating a new dataframe to represent the totals
summary_data_h1c = {
    "Version Type": ["Sample Downloads", "Premium Downloads"],
    "Total Downloads": [total_sample_downloads, total_premium_downloads]
}
df_summary_h1c = pd.DataFrame(summary_data_h1c)

# Creating a pie chart to show the proportion of sample vs premium downloads
fig, ax = plt.subplots(figsize=(3, 3))
ax.pie(df_summary_h1c['Total Downloads'], labels=df_summary_h1c['Version Type'], autopct='%1.1f%%', startangle=140)

plt.show()
```

High disparity is also evident in the average downloads, as shown in @tbl-premium-sample-diff. Where the average download difference is close to 500.000. With an average download ratio of nearly 27%. Meaning that about one in fourth users that download the sample app, also download the premium app.

```{python}
#| label: tbl-premium-sample-diff
#| tbl-cap: "Sample and Premium download metrics"
#| echo: false
#| warning: false
#| error: false

df_sample_h1c = df_level_combined[df_level_combined['level'] == '2 (Sample)']
df_premium_h1c = df_level_combined[df_level_combined['level'] == '2 (Premium)']
df_mapping_h1c = df_mapping_level_2.copy()

# relevant columns
relevant_columns_h1c = ['my_app_id', 'num_downloads', 'level', 'rating_app']
relevant_columns_mapping_h1c =  ['Sample app name',	'Premium app name']

# filter the relevant columns
df_sample_h1c = df_sample_h1c[relevant_columns_h1c]
df_premium_h1c = df_premium_h1c[relevant_columns_h1c]
df_mapping_h1c = df_mapping_h1c[relevant_columns_mapping_h1c]

# Merge mapping dataframe with sample dataframe and premium dataframe
df_mapped_h1c = (
    df_mapping_h1c
    .merge(df_sample_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Sample app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Sample Downloads', 'rating_app': 'Sample Rating'})
    .merge(df_premium_h1c[['my_app_id', 'num_downloads', 'rating_app']], left_on='Premium app name', right_on='my_app_id', how='left')
    .drop(columns=['my_app_id'])
    .rename(columns={'num_downloads': 'Premium Downloads', 'rating_app': 'Premium Rating'})
)

# Calculate metrics
df_mapped_h1c['Download Difference'] = df_mapped_h1c['Premium Downloads'] - df_mapped_h1c['Sample Downloads']
df_mapped_h1c['Download Ratio'] = df_mapped_h1c['Premium Downloads'] / df_mapped_h1c['Sample Downloads']


# Average downloads and ratios
avg_sample_downloads = df_mapped_h1c['Sample Downloads'].mean()
avg_premium_downloads = df_mapped_h1c['Premium Downloads'].mean()
avg_download_difference = df_mapped_h1c['Download Difference'].mean()
avg_download_ratio = df_mapped_h1c['Download Ratio'].mean()

# Data for the new dataframe
summary_data_h1c = {
    "Metric": [
        "Average Sample Downloads",
        "Average Premium Downloads",
        "Average Download Difference",
        "Average Download Ratio"
    ],
    "Value": [
        avg_sample_downloads,
        avg_premium_downloads,
        avg_download_difference,
        avg_download_ratio
    ]
}

# Create the summary dataframe
df_summary_h1c = pd.DataFrame(summary_data_h1c)
Markdown(tabulate(df_summary_h1c, headers=df_summary_h1c.columns))
```

Hypothesis H1c claims that sample versions have more downloads than their paid counterparts. @fig-total-average-downloads-by-level and @fig-total-average-downloads-by-level-2 show an imbalance in download rates, further supported by @fig-proportion-sample-premium and the disparities in @tbl-premium-sample-diff. These findings confirm H1c, and the hypothesis is accepted.

### Games in the Google Play Store {#sec-gaming-apps}

This section tests H1d: Most downloaded gaming apps will fall under levels 3 and 4.

Levels 3 and 4 show high total and average downloads (@fig-total-average-downloads-by-level). Games, making up 15.5% of apps (@fig-proportion-games-total-downloads-2), account for 26.7% of total downloads (@fig-proportion-games-total-downloads-1), with average downloads 98.6% higher than other apps (@tbl-avg-downloads-games).

```{python}
#| label: fig-proportion-games-total-downloads
#| fig-cap: "Proportion of Games compared to other apps"
#| fig-subcap:
#|   - "Total Downloads: Gaming vs Other Apps"
#|   - "Total Amount: Gaming vs Other Apps"
#| layout-ncol: 2
#| echo: false
#| warning: false
#| error: false

all_apps = df_level_combined.copy()

gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter other than gaming apps
other_apps = all_apps[~all_apps['categ_app'].isin(gaming_categories)]


df_level_combined_h1d = df_level_combined.copy()

# relevant columns
relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]

# Creating a list of categories that can be considered as part of the gaming category
gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter on games category
df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]

gaming_apps = df_level_combined_h1d.copy()

# relevant columns
relevant_columns_other_apps = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
other_apps = other_apps[relevant_columns_other_apps]

# Calculate the sum of downloads for each category
total_downloads_gaming_apps = gaming_apps['num_downloads'].sum()
total_downloads_other_apps = other_apps['num_downloads'].sum()
avg_downloads_gaming_apps = gaming_apps['num_downloads'].mean()
avg_downloads_other_apps = other_apps['num_downloads'].mean()
total_amount_gaming_apps = len(gaming_apps)
total_amount_other_apps = len(other_apps)

# Creating a new dataframe to represent the totals
summary_data = {
    "Category": ["Gaming Apps", "Other Apps"],
    "Total Downloads": [total_downloads_gaming_apps, total_downloads_other_apps],
    "Total Amount": [total_amount_gaming_apps, total_amount_other_apps],
    "Average Downloads": [avg_downloads_gaming_apps, avg_downloads_other_apps]

}
df_summary = pd.DataFrame(summary_data)

# Pie chart for Total Downloads
wedges1, texts1, autotexts1 = plt.pie(
    df_summary['Total Downloads'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140
)
plt.legend(wedges1, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9))
plt.tight_layout()
plt.show()

# Pie chart for Total Amount
wedges2, texts2, autotexts2 = plt.pie(
    df_summary['Total Amount'], labels=df_summary['Category'], autopct='%1.1f%%', startangle=140
)
plt.legend(wedges2, df_summary['Category'], title="Categories", loc="upper right", bbox_to_anchor=(1.3, 0.9))
plt.tight_layout()
plt.show()
```

```{python}
#| label: tbl-avg-downloads-games
#| tbl-cap: "Average Downloads Games vs Other Apps"
#| echo: false
#| warning: false
#| error: false

# Combine both datasets
all_apps = pd.concat([gaming_apps, other_apps])

# Calculate averages
gaming_avg = gaming_apps['num_downloads'].mean()
other_avg = other_apps['num_downloads'].mean()
overall_avg = all_apps['num_downloads'].mean()

# Percentage difference between gaming apps and overall average
gaming_vs_baseline_difference = ((gaming_avg - overall_avg) / overall_avg) * 100

# Percentage difference between other apps and overall average
other_vs_baseline_difference = ((other_avg - overall_avg) / overall_avg) * 100

# Percentage difference between gaming apps and other apps
gaming_vs_other_difference = ((gaming_avg - other_avg) / other_avg) * 100

# Create a summary table with shorter column names
summary_table = pd.DataFrame({
    'Category': ['Gaming', 'Other', 'All'],
    'Avg Downloads': [gaming_avg, other_avg, overall_avg],
    '% Diff Gaming vs Other': [
        gaming_vs_other_difference.round(2), 
        (gaming_vs_other_difference * -1).round(2), 
        "-"  # No comparison for the baseline
    ]
})

# Round the values for better readability
summary_table = summary_table.round(2)
Markdown(tabulate(summary_table, headers=summary_table.columns))
```

Up until now, these findings suggest that games are hugely popular, regardless of their revenue level. @fig-avg-downloads-level-3-4 shows that particularly games in levels 3 and 4 accrue a lot of downloads, compared to other levels.

```{python}
#| label: fig-avg-downloads-level-3-4
#| fig-cap: "Average amount of Downloads for Gaming Apps by Level"
#| echo: false
#| warning: false
#| error: false

df_level_combined_h1d = df_level_combined.copy()

# relevant columns
relevant_columns_h1d = ['my_app_id', 'num_downloads', 'level', 'categ_app']

# filter the relevant columns
df_level_combined_h1d = df_level_combined_h1d[relevant_columns_h1d]

# Creating a list of categories that can be considered as part of the gaming category
gaming_categories = [
    "Puzzle", "Casual", "Arcade", "Simulation", "Action", "Adventure", 
    "Trivia", "Racing", "Educational", "Card", "Word", "Board", 
    "Casino", "Role Playing", "Strategy", "Brain Games", 
    "Action & Adventure", "Pretend Play"
]

# Filter on games category
df_level_combined_h1d = df_level_combined_h1d[df_level_combined_h1d['categ_app'].isin(gaming_categories)]

# Adjusting the figure size
plt.figure(figsize=(5, 3))  # Width and height in inches

# Barplot of the number of downloads for each level
sns.barplot(data=df_level_combined_h1d, x='level', y='num_downloads', palette='viridis', order=level_order)
plt.xlabel('Level')
plt.ylabel('Number of Downloads')
plt.xticks(rotation=90)  # Rotate x-axis labels
plt.tight_layout()  # Ensures everything fits within the figure area
plt.show()

```

Games on the Google Play Store account for 26.7% of total downloads (@fig-proportion-games-total-downloads-1), with average downloads nearly doubling those of other apps at \~0.5 million (@tbl-avg-downloads-games). In levels 3 and 4, average downloads exceed 1 million (@fig-avg-downloads-level-3-4). These findings provide sufficient evidence to support H1d.

## Ratings

In this section, we will venture to answer hypothesis H2a and H2b. In @sec-quality-free-paid-apps, we will try to find fluctuations in ratings that might be by the quality in order to answer hypothesis H2a and H2b.

### Quality of Free and Paid Apps {#sec-quality-free-paid-apps}

This section tests the following hypotheses:

H2a: Apps requiring payment to unlock features (levels 2, 3, and 4) will have lower ratings than upfront payment apps (level 5).

H2b: Free-to-access apps (levels 0 and 1) will show greater rating variance due to varying quality.

According to @fig-free-vs-paid, premium apps have higher average ratings than free apps requiring payment to unlock features, while free apps display greater rating variability.

```{python}
#| label: fig-free-vs-paid
#| fig-cap: "Boxplot of Ratings for Free and Premium Apps"
#| echo: false
#| warning: false
#| error: false

df_level_combined_h2a = df_level_combined.copy()

# Filter only levels 2, 3, 4, and 5
df_h2a = df_level_combined_h2a[df_level_combined_h2a['level'].isin(['2 (Sample)', '2 (Premium)', '3', '4', '5'])].copy()

# Filter on premium and free apps
df_h2a['category'] = np.where((df_h2a['level'] == '5') | (df_h2a['level'] == '2 (Premium)'), 'Premium apps', 'Free apps')

# relevant columns
relevant_columns_h2a = ['category', 'rating_app', 'bayesian_average']

# filter the relevant columns
df_h2a = df_h2a[relevant_columns_h2a]

# Calculating the mean rating for Free and Premium apps
mean_rating_free = df_h2a[df_h2a['category'] == 'Free apps']['rating_app'].mean()
mean_rating_premium = df_h2a[df_h2a['category'] == 'Premium apps']['rating_app'].mean()

# Calculating the mean Bayesian average for Free and Premium apps
mean_bayesian_free = df_h2a[df_h2a['category'] == 'Free apps']['bayesian_average'].mean()
mean_bayesian_premium = df_h2a[df_h2a['category'] == 'Premium apps']['bayesian_average'].mean()

# Creating a new DataFrame from these results
mean_results = pd.DataFrame({
    'Category': ['Free apps', 'Premium apps'],
    'Mean Rating': [mean_rating_free, mean_rating_premium],
    'Mean Bayesian Average': [mean_bayesian_free, mean_bayesian_premium]
})

# Combine ratings for boxplot
categories = ['Free apps', 'Premium apps']
ratings_data = [df_h2a[df_h2a['category'] == cat]['rating_app'] for cat in categories]

plt.figure(figsize=(5, 3))
plt.boxplot(ratings_data, labels=categories, patch_artist=True)
plt.ylabel('Ratings')
plt.xlabel('App Category')
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

Paid apps have higher average ratings than free apps (@fig-free-vs-paid), indicating perceived higher quality, while the wider spread in free app ratings supports H2a.

Levels 0 and 1, with free access to all features, lead in downloads (\~40 billion; @tbl-downloads-free-access). H2b suggests rating variance reflects quality disparity, but minimal differences in variance and standard deviation (@tbl-free-access) indicate no significant difference.

```{python}
#| label: tbl-free-access
#| tbl-cap: "Variance (and std) difference. Between free access to all feature apps and free access to not all features or paid apps"
#| echo: false
#| warning: false
#| error: false


df_h1a = df_level_combined.copy()

# if level is 0 or 1 then new column category is 'Free apps'
df_h1a['category'] = ['Free all access' if level in ['0', '1'] else 'Freemium and Premium' for level in df_h1a['level']]

# Calculate variance and standard deviation for each category
df_stats_h1a = df_h1a.groupby('category')['rating_app'].agg(['var', 'std']).reset_index()

# Rename columns for clarity
df_stats_h1a.rename(columns={'var': 'variance in rating', 'std': 'standard deviation in rating'}, inplace=True)

Markdown(tabulate(df_stats_h1a, headers=df_stats_h1a.columns))
```

@fig-free-access visualizes variance with outliers. It shows that both categories have a similar median rating close to 4.5, with "Free/Paid not all feature apps" being slightly lower. Both categories seem to have a lot of outliers under 3, with 'free all feature apps' having more outliers in 2 and 1.

```{python}
#| label: fig-free-access
#| fig-cap: "Boxplot of Ratings by App Category"
#| echo: false
#| warning: false
#| error: false

# Step 1: Add 'category' column based on level
df_h1a = df_level_combined.copy()
df_h1a['category'] = [
    'Free all feature apps' if level in ['0', '1'] else 'Free/Paid not all feature apps' 
    for level in df_h1a['level']
]

# Step 3: Create a boxplot for ratings categorized by 'category'

# Prepare data for custom boxplot
categories = df_h1a['category'].unique()
ratings_data = [df_h1a[df_h1a['category'] == category]['rating_app'] for category in categories]

# Custom boxplot
plt.figure(figsize=(5, 3))
plt.boxplot(ratings_data, labels=categories, patch_artist=True)
plt.ylabel('Ratings')
plt.xlabel('App Category')
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()
```

The variance and standard deviation between the two categories are minimal (@tbl-free-access). @fig-free-access shows both receive high ratings, with notable outliers reflecting variability in user satisfaction. The slightly higher median for "Free all feature apps" suggests a preference but is marginal and likely requires statistical validation. Thus, evidence for greater variance in levels 0 and 1 is inconclusive, and H2b is rejected.

## Conclusion

The six revenue strategies by @djaruma2023 show distinct trade-offs between accessibility and user satisfaction.

Levels 0 and 1 dominate with \~40 billion downloads but have variable ratings, prioritizing accessibility over quality. Freemium models (levels 2, 3, and 4) balance popularity and user expectations, while fully premium apps (level 5) achieve the highest, most consistent ratings but limited reach.

Games account for 26.7% of downloads (@fig-proportion-games-total-downloads-1) and average nearly double the downloads of other apps (\~0.5M, @tbl-avg-downloads-games). Levels 3 and 4 surpass 1M average downloads (@fig-avg-downloads-level-3-4), supporting H1d.

In summary, free models maximize reach, freemium models balance flexibility and satisfaction, and premium models prioritize quality. Each strategy meets different user needs.

## Ethical Considerations

This research uses publicly available Google Play Store data, ensuring user privacy [@tikkinen-piri2018]. However, such data can reveal sensitive business insights, like proprietary strategies. To mitigate this, we avoid highlighting specific apps. The findings offer value to developers, marketers, and policymakers by revealing profitable monetization methods, but they also raise ethical concerns, potentially encouraging exploitative practices that prioritize profits over user experience [@mileros2024]. This highlights the need to balance actionable insights with ethical responsibility.

# Discussion <!--500-700 words -->

This study examined the relationship between six revenue strategies and app success, measured by downloads and ratings. The findings reveal clear trade-offs among these models, offering insights into app monetization strategies.

## Reflection on the Findings

We found that free apps (Levels 0 and 1) dominate in terms of downloads. However, these apps also have higher variance in ratings, suggesting they struggle with consistent quality. While this aligns with existing literature suggesting that free apps attract a broad audience but often deliver inconsistent experiences [@mileros2024], it does raise the question of whether the amount of downloads should be the primary measure of success. Free apps may have more downloads, but without understanding the deeper dynamics of user engagement and satisfaction, these figures could be misleading. For example, apps with high ratings but fewer downloads could still represent significant success in specific niches.

Freemium models (Levels 2 and 3) show promise as a balanced strategy, combining accessibility with opportunities for revenue generation. These models cater to both casual users and those willing to pay for premium features, reflecting their flexibility. Prior research supports this notion, emphasizing the interplay between user retention and monetization in freemium models [@kumar2014]. However, the disparity in downloads between sample and premium versions suggests that other factors, such as app quality or external influences like marketing, also play significant roles in shaping success [@stocchi2022].

Premium apps (Level 5) stand out for their high average ratings, reinforcing the perception of superior quality. This is consistent with user expectations: those who pay upfront often demand a polished product. However, premium apps trade reach for exclusivity, as shown by their lower download numbers. This dynamic aligns with theories of optimal distinctiveness, where firms strive to balance conformity to market norms with differentiation to reduce competition [@Zhao2018]. For premium apps, moderate differentiation appears optimal, allowing for high-quality perceptions while catering to a specific user base.

This finding aligns with the broader literature on optimal distinctiveness, which explores how firms should manage the balance between conformity and differentiation in order to achieve superior performance [@Zhao2018]. On the one hand, products need to conform to category norms to build legitimacy, but on the other hand, they should differ enough to avoid intense competition. The study by [@vanangeren2022] further extends this line of inquiry by considering how the relationship between differentiation and performance varies based on the product’s revenue model. For premium apps, moderate differentiation appears to be an optimal strategy, allowing for both quality perception and enough market fit, but with the trade-off of a smaller, more specific user base.

## Limitations

This study has several limitations. Downloads are not a comprehensive measure of app success, particularly for freemium models. Metrics such as user retention, in-app purchases, and time spent on the app may better reflect profitability and user engagement [@ross2018]. Additionally, the dataset predates the rise of TikTok, a platform whose unique revenue model could alter findings, particularly for levels emphasizing in-app purchases (e.g., Level 3). Including more recent data could provide a fuller picture of trends and revenue strategies.

Causality is another challenge. While the study identifies correlations between revenue models, downloads, and ratings, these relationships are influenced by external factors such as marketing efforts, app category, and regional preferences. Therefore, the results should not be interpreted as causal. Moreover, the exclusion of revenue estimates due to data limitations prevents deeper insights into profitability, a critical dimension of app success.

## Practical Implications for Businesses

For app developers, these findings offer valuable guidance. Free models (Levels 0 and 1) are effective for maximizing reach, but ensuring quality remains critical to sustaining user engagement. Freemium models provide a flexible approach, appealing to both casual users and paying customers. However, success in these models requires a strong focus on user retention and feature quality. Premium models, while catering to niche audiences, demand significant investment in quality to meet high user expectations.

Businesses should consider these trade-offs when selecting a revenue model, aligning their choices with the app’s target audience and objectives. However, over-reliance on these findings should be avoided, as they reflect correlations rather than definitive success drivers.

## Future Research Directions

Future studies should address limitations by integrating newer datasets that include platforms like TikTok and expanding metrics to capture user engagement and in-app purchases. Exploring additional dimensions of app success, such as long-term user retention, would provide a more nuanced understanding of monetization strategies.

Ongoing research is crucial in this dynamic field. By building on these findings, future work can contribute to more effective and user-centric app monetization strategies, supporting businesses in navigating the ever-evolving app market.

# References

::: {#refs}
:::
